#!/usr/bin/env python3
"""
NKAT-llama.cpp çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•-ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã‚’llama.cppã«çµ±åˆ
"""

import os
import shutil
import logging
from pathlib import Path
from tqdm import tqdm
import json
from datetime import datetime

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('nkat_llama_integration.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class NKATLlamaCppIntegrator:
    def __init__(self):
        self.base_dir = Path(".")
        self.llama_cpp_dir = self.base_dir / "llama.cpp"
        self.output_dir = self.base_dir / "output" / "cuda_kernels"
        self.cuda_dir = self.llama_cpp_dir / "ggml" / "src" / "ggml-cuda"
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.backup_dir = self.base_dir / "emergency_backups" / f"nkat_integration_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        print("ğŸŒŸ NKAT-llama.cpp çµ±åˆã‚·ã‚¹ãƒ†ãƒ  v1.0")
        print("=" * 50)
        logger.info("ğŸŒŸ NKAT-llama.cppçµ±åˆé–‹å§‹")
        
    def create_backup(self):
        """é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        try:
            print("ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆä¸­...")
            self.backup_dir.mkdir(parents=True, exist_ok=True)
            
            # llama.cppã®é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            backup_files = [
                "CMakeLists.txt",
                "ggml/src/ggml-cuda/common.cuh",
                "ggml/src/ggml.c",
                "src/llama.cpp"
            ]
            
            for file_path in tqdm(backup_files, desc="ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"):
                src = self.llama_cpp_dir / file_path
                if src.exists():
                    dst = self.backup_dir / file_path
                    dst.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(src, dst)
                    
            logger.info(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {self.backup_dir}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—: {str(e)}")
            return False
    
    def copy_nkat_files(self):
        """NKATãƒ•ã‚¡ã‚¤ãƒ«ã‚’llama.cppã«ã‚³ãƒ”ãƒ¼"""
        try:
            print("ğŸ“ NKATãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ä¸­...")
            
            # CUDAãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            if not self.cuda_dir.exists():
                logger.error(f"âŒ CUDAãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.cuda_dir}")
                return False
                
            file_mappings = {
                "nkat_star_gemm_kernels.cu": self.cuda_dir / "nkat_star_gemm_kernels.cu",
                "nkat_cuda_interface.cpp": self.cuda_dir / "nkat_cuda_interface.cpp", 
                "nkat_cuda.h": self.cuda_dir / "nkat_cuda.h"
            }
            
            for src_name, dst_path in tqdm(file_mappings.items(), desc="ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼"):
                src_path = self.output_dir / src_name
                if src_path.exists():
                    shutil.copy2(src_path, dst_path)
                    logger.info(f"ğŸ“„ ã‚³ãƒ”ãƒ¼å®Œäº†: {src_name} â†’ {dst_path}")
                else:
                    logger.warning(f"âš ï¸ ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹: {src_path}")
                    
            return True
            
        except Exception as e:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼å¤±æ•—: {str(e)}")
            return False
    
    def modify_cmake_lists(self):
        """CMakeLists.txtã«NKATè¨­å®šã‚’è¿½åŠ """
        try:
            print("âš™ï¸ CMakeLists.txtæ›´æ–°ä¸­...")
            
            cmake_file = self.llama_cpp_dir / "CMakeLists.txt"
            if not cmake_file.exists():
                logger.error(f"âŒ CMakeLists.txtãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {cmake_file}")
                return False
                
            # ç¾åœ¨ã®å†…å®¹ã‚’èª­ã¿è¾¼ã¿
            with open(cmake_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # NKATè¨­å®šã‚’è¿½åŠ ï¼ˆGGML_CUDAä½¿ç”¨ï¼‰
            nkat_cmake_addition = """
# NKAT (Non-commutative Kolmogorov-Arnold Theory) Integration
option(LLAMA_NKAT "Enable NKAT support" ON)

if(LLAMA_NKAT AND GGML_CUDA)
    message(STATUS "ğŸŒŸ NKAT enabled with CUDA support")
    add_compile_definitions(GGML_USE_NKAT)
    
    # NKAT specific CUDA flags
    set(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} -DGGML_CUDA_NKAT_ENABLED")
    set(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} --use_fast_math -O3")
    set(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} --maxrregcount=64")
    set(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} --gpu-architecture=sm_86")
    
    # Add NKAT source files to ggml-cuda
    target_sources(ggml-cuda PRIVATE
        ggml/src/ggml-cuda/nkat_star_gemm_kernels.cu
        ggml/src/ggml-cuda/nkat_cuda_interface.cpp
    )
endif()
"""
            
            # CUDAè¨­å®šã®å¾Œã«è¿½åŠ 
            if "GGML_CUDA" in content and "NKAT" not in content:
                # é©åˆ‡ãªä½ç½®ã‚’è¦‹ã¤ã‘ã¦è¿½åŠ 
                lines = content.split('\n')
                insert_pos = len(lines)
                
                for i, line in enumerate(lines):
                    if "endif()" in line and "GGML_CUDA" in lines[max(0, i-20):i]:
                        insert_pos = i + 1
                        break
                        
                lines.insert(insert_pos, nkat_cmake_addition)
                content = '\n'.join(lines)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãæˆ»ã—
                with open(cmake_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                    
                logger.info("âœ… CMakeLists.txtæ›´æ–°å®Œäº†")
                return True
            else:
                logger.info("â„¹ï¸ NKATè¨­å®šã¯æ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ã€CUDAè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return True
                
        except Exception as e:
            logger.error(f"âŒ CMakeLists.txtæ›´æ–°å¤±æ•—: {str(e)}")
            return False
    
    def modify_ggml_cuda_common(self):
        """ggml-cuda/common.cuhã«NKATãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ """
        try:
            print("ğŸ”§ CUDAå…±é€šãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°ä¸­...")
            
            common_file = self.cuda_dir / "common.cuh"
            if not common_file.exists():
                logger.warning(f"âš ï¸ common.cuhãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {common_file}")
                return True  # è‡´å‘½çš„ã§ã¯ãªã„
                
            with open(common_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # NKATãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
            if "nkat_cuda.h" not in content:
                nkat_include = '\n#ifdef GGML_CUDA_NKAT_ENABLED\n#include "nkat_cuda.h"\n#endif\n'
                
                # é©åˆ‡ãªä½ç½®ã«ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ãƒ‰ã‚’è¿½åŠ 
                if "#pragma once" in content:
                    content = content.replace("#pragma once", "#pragma once" + nkat_include)
                else:
                    content = nkat_include + content
                    
                with open(common_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                    
                logger.info("âœ… CUDAå…±é€šãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°å®Œäº†")
            else:
                logger.info("â„¹ï¸ NKATãƒ˜ãƒƒãƒ€ãƒ¼ã¯æ—¢ã«è¿½åŠ æ¸ˆã¿")
                
            return True
            
        except Exception as e:
            logger.error(f"âŒ CUDAå…±é€šãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°å¤±æ•—: {str(e)}")
            return False
    
    def build_with_nkat(self):
        """NKATæœ‰åŠ¹ã§ãƒ“ãƒ«ãƒ‰å®Ÿè¡Œ"""
        try:
            print("ğŸ”¨ NKATçµ±åˆãƒ“ãƒ«ãƒ‰é–‹å§‹...")
            
            build_dir = self.llama_cpp_dir / "build_nkat"
            build_dir.mkdir(exist_ok=True)
            
            os.chdir(build_dir)
            
            # CMakeè¨­å®šï¼ˆNKATæœ‰åŠ¹ã€GGML_CUDAä½¿ç”¨ï¼‰
            cmake_cmd = [
                "cmake", "..",
                "-G", "Visual Studio 16 2019",
                "-A", "x64",
                "-DGGML_CUDA=ON",
                "-DLLAMA_NKAT=ON",
                "-DCMAKE_BUILD_TYPE=Release",
                "-DCUDA_ARCHITECTURES=86",
                "-DCUDA_TOOLKIT_ROOT_DIR=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8"
            ]
            
            logger.info(f"ğŸ”§ CMakeè¨­å®šå®Ÿè¡Œ: {' '.join(cmake_cmd)}")
            
            import subprocess
            result = subprocess.run(cmake_cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.error(f"âŒ CMakeè¨­å®šå¤±æ•—:\n{result.stderr}")
                return False
                
            # ãƒ“ãƒ«ãƒ‰å®Ÿè¡Œ
            build_cmd = ["cmake", "--build", ".", "--config", "Release", "--target", "llama-cli", "--parallel", "4"]
            logger.info(f"ğŸ”¨ ãƒ“ãƒ«ãƒ‰å®Ÿè¡Œ: {' '.join(build_cmd)}")
            
            result = subprocess.run(build_cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.error(f"âŒ ãƒ“ãƒ«ãƒ‰å¤±æ•—:\n{result.stderr}")
                return False
                
            logger.info("âœ… NKATçµ±åˆãƒ“ãƒ«ãƒ‰å®Œäº†")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ãƒ“ãƒ«ãƒ‰å¤±æ•—: {str(e)}")
            return False
        finally:
            os.chdir(self.base_dir)
    
    def verify_integration(self):
        """çµ±åˆã®æ¤œè¨¼"""
        try:
            print("ğŸ” çµ±åˆæ¤œè¨¼ä¸­...")
            
            # ãƒ“ãƒ«ãƒ‰ã•ã‚ŒãŸå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªï¼ˆæ–°ã—ã„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåï¼‰
            main_exe = self.llama_cpp_dir / "build_nkat" / "bin" / "Release" / "llama-cli.exe"
            if not main_exe.exists():
                main_exe = self.llama_cpp_dir / "build_nkat" / "Release" / "llama-cli.exe"
                
            if main_exe.exists():
                logger.info(f"âœ… å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {main_exe}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
                file_size = main_exe.stat().st_size / (1024 * 1024)
                logger.info(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f} MB")
                
                return True
            else:
                logger.error("âŒ å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
                
        except Exception as e:
            logger.error(f"âŒ çµ±åˆæ¤œè¨¼å¤±æ•—: {str(e)}")
            return False
    
    def generate_integration_report(self, success):
        """çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            report = {
                "timestamp": datetime.now().isoformat(),
                "integration_success": success,
                "nkat_version": "0.2",
                "cuda_architecture": "sm_86",
                "backup_location": str(self.backup_dir),
                "files_integrated": [
                    "nkat_star_gemm_kernels.cu",
                    "nkat_cuda_interface.cpp", 
                    "nkat_cuda.h"
                ],
                "build_configuration": {
                    "ggml_cuda": True,
                    "llama_nkat": True,
                    "cmake_generator": "Visual Studio 16 2019",
                    "cuda_toolkit": "v12.8"
                }
            }
            
            report_file = self.base_dir / "nkat_integration_report.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
                
            logger.info(f"ğŸ“Š çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_file}")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¤±æ•—: {str(e)}")
    
    def run_integration(self):
        """çµ±åˆãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œ"""
        success = False
        
        try:
            # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
            steps = [
                ("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ", self.create_backup),
                ("NKATãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼", self.copy_nkat_files),
                ("CMakeLists.txtæ›´æ–°", self.modify_cmake_lists),
                ("CUDAå…±é€šãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°", self.modify_ggml_cuda_common),
                ("NKATçµ±åˆãƒ“ãƒ«ãƒ‰", self.build_with_nkat),
                ("çµ±åˆæ¤œè¨¼", self.verify_integration)
            ]
            
            for step_name, step_func in steps:
                print(f"\nğŸ”„ {step_name}...")
                if not step_func():
                    logger.error(f"âŒ {step_name}ã§å¤±æ•—ã—ã¾ã—ãŸ")
                    break
            else:
                success = True
                print("\nğŸ‰ NKAT-llama.cppçµ±åˆå®Œäº†!")
                print("=" * 50)
                print("ğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
                print("   1. cd llama.cpp/build_nkat/Release")
                print("   2. ./llama-cli.exe -m ../../../models/test/sample.gguf --nkat-enable")
                print("   3. Moyal star product ã«ã‚ˆã‚‹éå¯æ›æ¨è«–ã‚’ä½“é¨“")
                
        except Exception as e:
            logger.error(f"âŒ çµ±åˆãƒ—ãƒ­ã‚»ã‚¹å¤±æ•—: {str(e)}")
        finally:
            self.generate_integration_report(success)
            
        return success

def main():
    integrator = NKATLlamaCppIntegrator()
    return integrator.run_integration()

if __name__ == "__main__":
    main() 