#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ—‚ï¸ NKAT-GGUF ãƒªãƒã‚¸ãƒˆãƒªæ•´ç†ã‚·ã‚¹ãƒ†ãƒ 
ãƒªãƒã‚¸ãƒˆãƒªã®æ§‹é€ ã‚’æœ€é©åŒ–ã—ã€ä¸è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™
"""

import os
import shutil
import json
import hashlib
from pathlib import Path
from datetime import datetime
from tqdm import tqdm

class RepositoryOrganizer:
    """ãƒªãƒã‚¸ãƒˆãƒªæ•´ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, repo_path="."):
        self.repo_path = Path(repo_path)
        self.backup_root = self.repo_path / "emergency_backups"
        self.backup_root.mkdir(exist_ok=True)
        
        # æ•´ç†çµ±è¨ˆ
        self.stats = {
            "deleted_files": 0,
            "moved_files": 0,
            "duplicates_removed": 0,
            "space_saved_mb": 0,
            "errors": []
        }
        
    def create_backup(self):
        """æ•´ç†å‰ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        print("ğŸ“¦ æ•´ç†å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆä¸­...")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = self.backup_root / f"pre_organization_{timestamp}"
        
        try:
            # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            important_files = [
                "README.md", "PROJECT_SUMMARY.md", "requirements.txt",
                "file_history.json", ".gitignore"
            ]
            
            backup_dir.mkdir(exist_ok=True)
            for file_name in important_files:
                file_path = self.repo_path / file_name
                if file_path.exists():
                    shutil.copy2(file_path, backup_dir)
                    
            print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå®Œäº†: {backup_dir}")
            return backup_dir
        except Exception as e:
            print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def analyze_duplicates(self):
        """é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º"""
        print("ğŸ” é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºä¸­...")
        file_hashes = {}
        duplicates = []
        
        # é™¤å¤–ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        exclude_dirs = {".git", ".specstory", "__pycache__", "emergency_backups"}
        
        for file_path in self.repo_path.rglob("*"):
            if (file_path.is_file() and 
                not any(excluded in str(file_path) for excluded in exclude_dirs)):
                
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
                    with open(file_path, 'rb') as f:
                        file_hash = hashlib.md5(f.read()).hexdigest()
                    
                    if file_hash in file_hashes:
                        duplicates.append((file_path, file_hashes[file_hash]))
                    else:
                        file_hashes[file_hash] = file_path
                        
                except Exception as e:
                    self.stats["errors"].append(f"ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
        
        return duplicates
    
    def remove_temporary_files(self):
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
        print("ğŸ§¹ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ä¸­...")
        
        temp_patterns = [
            "*.tmp", "*.temp", "*.pyc", "*.log", "*.bak",
            "Thumbs.db", ".DS_Store", "*.swp", "*.swo"
        ]
        
        deleted_count = 0
        deleted_size = 0
        
        for pattern in temp_patterns:
            for file_path in self.repo_path.rglob(pattern):
                try:
                    if file_path.is_file():
                        size = file_path.stat().st_size
                        file_path.unlink()
                        deleted_count += 1
                        deleted_size += size
                        
                except Exception as e:
                    self.stats["errors"].append(f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
        
        self.stats["deleted_files"] += deleted_count
        self.stats["space_saved_mb"] += deleted_size / (1024 * 1024)
        
        print(f"ğŸ—‘ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {deleted_count}å€‹, {deleted_size/(1024*1024):.2f}MB")
    
    def organize_models_directory(self):
        """modelsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ•´ç†"""
        print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ•´ç†ä¸­...")
        
        models_dir = self.repo_path / "models"
        if not models_dir.exists():
            return
            
        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        test_models = models_dir / "test"
        demo_models = models_dir / "demo"
        integrated_models = models_dir / "integrated"
        
        for subdir in [test_models, demo_models, integrated_models]:
            subdir.mkdir(exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†é¡ã¨ç§»å‹•
        for file_path in models_dir.iterdir():
            if file_path.is_file() and file_path.suffix == ".gguf":
                name = file_path.name.lower()
                
                try:
                    if "test" in name:
                        target = test_models / file_path.name
                    elif "demo" in name:
                        target = demo_models / file_path.name
                    elif "integrated" in name:
                        target = integrated_models / file_path.name
                    else:
                        continue  # ãƒ«ãƒ¼ãƒˆã«æ®‹ã™
                    
                    if not target.exists():
                        shutil.move(str(file_path), str(target))
                        self.stats["moved_files"] += 1
                        
                except Exception as e:
                    self.stats["errors"].append(f"ç§»å‹•ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
    
    def clean_integrity_backups(self):
        """æ•´åˆæ€§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®é‡è¤‡å‰Šé™¤"""
        print("ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†ä¸­...")
        
        integrity_dir = self.repo_path / "integrity_backups"
        if not integrity_dir.exists():
            return
        
        # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆã—ã¦æœ€æ–°3ã¤ä»¥å¤–å‰Šé™¤
        backup_files = list(integrity_dir.glob("*.gguf"))
        backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤ï¼ˆæœ€æ–°3ã¤ã‚’ä¿æŒï¼‰
        for file_path in backup_files[3:]:
            try:
                size = file_path.stat().st_size
                file_path.unlink()
                self.stats["deleted_files"] += 1
                self.stats["space_saved_mb"] += size / (1024 * 1024)
                print(f"ğŸ—‘ï¸ å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤: {file_path.name}")
                
            except Exception as e:
                self.stats["errors"].append(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
    
    def update_gitignore(self):
        """gitignoreãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°"""
        print("ğŸ“ .gitignoreæ›´æ–°ä¸­...")
        
        gitignore_path = self.repo_path / ".gitignore"
        
        additional_ignores = [
            "# Python ã‚­ãƒ£ãƒƒã‚·ãƒ¥",
            "__pycache__/",
            "*.pyc",
            "*.pyo",
            "*.pyd",
            "",
            "# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«",
            "*.tmp",
            "*.temp",
            "*.log",
            "*.bak",
            "",
            "# OSå›ºæœ‰",
            "Thumbs.db",
            ".DS_Store",
            "",
            "# IDE",
            ".vscode/",
            ".idea/",
            "",
            "# å¤§å®¹é‡ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
            "# *.gguf",
            "",
            "# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
            "emergency_backups/",
            "integrity_backups/*.gguf"
        ]
        
        try:
            if gitignore_path.exists():
                with open(gitignore_path, 'r', encoding='utf-8') as f:
                    current_content = f.read()
            else:
                current_content = ""
            
            # æ–°ã—ã„ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½åŠ 
            new_entries = []
            for entry in additional_ignores:
                if entry not in current_content:
                    new_entries.append(entry)
            
            if new_entries:
                with open(gitignore_path, 'a', encoding='utf-8') as f:
                    f.write("\n" + "\n".join(new_entries))
                print("âœ… .gitignoreæ›´æ–°å®Œäº†")
                
        except Exception as e:
            self.stats["errors"].append(f".gitignoreæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def create_organization_report(self):
        """æ•´ç†ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        print("ğŸ“Š æ•´ç†ãƒ¬ãƒãƒ¼ãƒˆä½œæˆä¸­...")
        
        report = {
            "organization_date": datetime.now().isoformat(),
            "statistics": self.stats,
            "directory_structure": self.get_directory_structure(),
            "recommendations": [
                "å®šæœŸçš„ãªä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„",
                "å¤§ããªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯Git LFSã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                "é–‹ç™ºä¸­ã¯ emergency_backups/ ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
            ]
        }
        
        report_path = self.repo_path / "ORGANIZATION_REPORT.md"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("# ğŸ—‚ï¸ ãƒªãƒã‚¸ãƒˆãƒªæ•´ç†ãƒ¬ãƒãƒ¼ãƒˆ\n\n")
                f.write(f"**æ•´ç†æ—¥æ™‚**: {report['organization_date']}\n\n")
                
                f.write("## ğŸ“Š æ•´ç†çµ±è¨ˆ\n\n")
                f.write(f"- å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {self.stats['deleted_files']}\n")
                f.write(f"- ç§»å‹•ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {self.stats['moved_files']}\n")
                f.write(f"- é‡è¤‡å‰Šé™¤æ•°: {self.stats['duplicates_removed']}\n")
                f.write(f"- ç¯€ç´„å®¹é‡: {self.stats['space_saved_mb']:.2f}MB\n")
                
                if self.stats["errors"]:
                    f.write("\n## âš ï¸ ã‚¨ãƒ©ãƒ¼\n\n")
                    for error in self.stats["errors"]:
                        f.write(f"- {error}\n")
                
                f.write("\n## ğŸ“ æ•´ç†å¾Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ \n\n")
                f.write("```\n")
                f.write(self.get_directory_tree())
                f.write("```\n")
                
            print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆä½œæˆå®Œäº†: {report_path}")
            
        except Exception as e:
            print(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_directory_structure(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ å–å¾—"""
        structure = {}
        exclude_dirs = {".git", ".specstory", "__pycache__", "emergency_backups"}
        
        for item in self.repo_path.iterdir():
            if item.is_dir() and item.name not in exclude_dirs:
                file_count = len(list(item.rglob("*")))
                structure[item.name] = file_count
        
        return structure
    
    def get_directory_tree(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ„ãƒªãƒ¼æ–‡å­—åˆ—ç”Ÿæˆ"""
        tree_lines = ["NKAT_GGUF/"]
        exclude_dirs = {".git", ".specstory", "__pycache__", "emergency_backups"}
        
        dirs = [d for d in self.repo_path.iterdir() 
               if d.is_dir() and d.name not in exclude_dirs]
        dirs.sort()
        
        for i, dir_path in enumerate(dirs):
            is_last = i == len(dirs) - 1
            prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
            file_count = len([f for f in dir_path.rglob("*") if f.is_file()])
            tree_lines.append(f"{prefix}{dir_path.name}/ ({file_count} files)")
        
        # ãƒ«ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
        root_files = [f for f in self.repo_path.iterdir() if f.is_file()]
        if root_files:
            tree_lines.append("â”œâ”€â”€ [root files]")
            for file_path in sorted(root_files):
                tree_lines.append(f"â”‚   â”œâ”€â”€ {file_path.name}")
        
        return "\n".join(tree_lines)
    
    def run_full_organization(self):
        """ãƒ•ãƒ«æ•´ç†å®Ÿè¡Œ"""
        print("ğŸš€ NKAT-GGUF ãƒªãƒã‚¸ãƒˆãƒªæ•´ç†é–‹å§‹")
        print("=" * 50)
        
        # 1. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_dir = self.create_backup()
        if not backup_dir:
            print("âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå¤±æ•—ã€‚æ•´ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
            return False
        
        try:
            # 2. é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
            duplicates = self.analyze_duplicates()
            if duplicates:
                print(f"âš ï¸ é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º: {len(duplicates)}çµ„")
                for dup_pair in duplicates:
                    print(f"  - {dup_pair[0]} â†â†’ {dup_pair[1]}")
            
            # 3. ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            self.remove_temporary_files()
            
            # 4. ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ•´ç†
            self.organize_models_directory()
            
            # 5. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†
            self.clean_integrity_backups()
            
            # 6. gitignoreæ›´æ–°
            self.update_gitignore()
            
            # 7. ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
            self.create_organization_report()
            
            print("\n" + "=" * 50)
            print("âœ… ãƒªãƒã‚¸ãƒˆãƒªæ•´ç†å®Œäº†!")
            print(f"ğŸ“Š å‰Šé™¤: {self.stats['deleted_files']}ãƒ•ã‚¡ã‚¤ãƒ«")
            print(f"ğŸ“ ç§»å‹•: {self.stats['moved_files']}ãƒ•ã‚¡ã‚¤ãƒ«")
            print(f"ğŸ’¾ ç¯€ç´„: {self.stats['space_saved_mb']:.2f}MB")
            
            if self.stats["errors"]:
                print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {len(self.stats['errors'])}ä»¶")
                print("è©³ç´°ã¯ ORGANIZATION_REPORT.md ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            
            return True
            
        except Exception as e:
            print(f"âŒ æ•´ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            print(f"ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©æ—§å¯èƒ½: {backup_dir}")
            return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ—‚ï¸ NKAT-GGUF ãƒªãƒã‚¸ãƒˆãƒªæ•´ç†ã‚·ã‚¹ãƒ†ãƒ ")
    
    organizer = RepositoryOrganizer()
    
    # ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    response = input("\næ•´ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
    if response not in ['y', 'yes']:
        print("æ•´ç†ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
        return
    
    # æ•´ç†å®Ÿè¡Œ
    success = organizer.run_full_organization()
    
    if success:
        print("\nğŸ‰ æ•´ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print("ğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: ORGANIZATION_REPORT.md")
    else:
        print("\nâŒ æ•´ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        print("ğŸ“¦ emergency_backups/ ã‹ã‚‰å¾©æ—§ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main() 