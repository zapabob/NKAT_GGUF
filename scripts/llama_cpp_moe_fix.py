#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”§ llama.cpp MoE (Mixture of Experts) é‡å­åŒ–ã‚¿ã‚¤ãƒ—ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ 
llama.cpp MoE Quantization Type Fix System

ç‰¹å¾´:
- MoEãƒ¢ãƒ‡ãƒ«ã®é‡å­åŒ–ã‚¿ã‚¤ãƒ—ä¸ä¸€è‡´ã‚’ä¿®å¾©
- å…¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®é‡å­åŒ–ã‚¿ã‚¤ãƒ—ã‚’çµ±ä¸€
- llama.cppæœ€æ–°ç‰ˆã¨ã®äº’æ›æ€§ç¢ºä¿
- NKATå¤‰æ›ã¨ã®çµ±åˆå¯¾å¿œ
- è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½

å‚è€ƒ: https://github.com/ggerganov/llama.cpp/discussions/9299
"""

import os
import sys
import struct
import shutil
import json
import tempfile
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('llama_cpp_moe_fix.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# GGUFå®šæ•°
GGUF_MAGIC = b'GGUF'
GGUF_VERSION = 3

# å‹å®šç¾©
GGUF_TYPE_UINT8 = 0
GGUF_TYPE_INT8 = 1
GGUF_TYPE_UINT16 = 2
GGUF_TYPE_INT16 = 3
GGUF_TYPE_UINT32 = 4
GGUF_TYPE_INT32 = 5
GGUF_TYPE_FLOAT32 = 6
GGUF_TYPE_BOOL = 7
GGUF_TYPE_STRING = 8
GGUF_TYPE_ARRAY = 9
GGUF_TYPE_UINT64 = 10
GGUF_TYPE_INT64 = 11
GGUF_TYPE_FLOAT64 = 12

# é‡å­åŒ–ã‚¿ã‚¤ãƒ—
GGML_TYPE_F32 = 0
GGML_TYPE_F16 = 1
GGML_TYPE_Q4_0 = 2
GGML_TYPE_Q4_1 = 3
GGML_TYPE_Q5_0 = 6
GGML_TYPE_Q5_1 = 7
GGML_TYPE_Q8_0 = 8
GGML_TYPE_Q8_1 = 9
GGML_TYPE_Q2_K = 10
GGML_TYPE_Q3_K = 11
GGML_TYPE_Q4_K = 12
GGML_TYPE_Q5_K = 13
GGML_TYPE_Q6_K = 14
GGML_TYPE_Q8_K = 15
GGML_TYPE_IQ2_XXS = 16
GGML_TYPE_IQ2_XS = 17
GGML_TYPE_IQ3_XXS = 18
GGML_TYPE_IQ1_S = 19
GGML_TYPE_IQ4_NL = 20
GGML_TYPE_IQ3_S = 21
GGML_TYPE_IQ2_S = 22
GGML_TYPE_IQ4_XS = 23
GGML_TYPE_I8 = 24
GGML_TYPE_I16 = 25
GGML_TYPE_I32 = 26
GGML_TYPE_I64 = 27
GGML_TYPE_F64 = 28
GGML_TYPE_IQ1_M = 29

# MoEé–¢é€£ã‚­ãƒ¼
MOE_METADATA_KEYS = [
    'llama.expert_count',
    'llama.expert_used_count',
    'general.architecture'
]

class LlamaCppMoEFixer:
    """llama.cpp MoEä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, backup_dir: str = "emergency_backups"):
        self.backup_dir = Path(backup_dir)
        self.backup_dir.mkdir(exist_ok=True)
        
        self.type_sizes = {
            GGUF_TYPE_UINT8: 1, GGUF_TYPE_INT8: 1,
            GGUF_TYPE_UINT16: 2, GGUF_TYPE_INT16: 2,
            GGUF_TYPE_UINT32: 4, GGUF_TYPE_INT32: 4, GGUF_TYPE_FLOAT32: 4,
            GGUF_TYPE_UINT64: 8, GGUF_TYPE_INT64: 8, GGUF_TYPE_FLOAT64: 8,
            GGUF_TYPE_BOOL: 1
        }
        
        logger.info(f"ğŸ”§ LlamaCppMoEFixer åˆæœŸåŒ–å®Œäº†")
        logger.info(f"   ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.backup_dir}")
    
    def create_backup(self, file_path: str) -> str:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = self.backup_dir / f"{Path(file_path).stem}_moe_backup_{timestamp}.gguf"
        shutil.copy2(file_path, backup_path)
        logger.info(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")
        return str(backup_path)
    
    def analyze_moe_model(self, file_path: str) -> Dict[str, Any]:
        """MoEãƒ¢ãƒ‡ãƒ«åˆ†æ"""
        logger.info(f"ğŸ” MoEãƒ¢ãƒ‡ãƒ«åˆ†æé–‹å§‹: {file_path}")
        
        try:
            with open(file_path, 'rb') as f:
                # ãƒ˜ãƒƒãƒ€ãƒ¼èª­ã¿å–ã‚Š
                header = self._read_header(f)
                if not header:
                    return {"status": "error", "message": "ç„¡åŠ¹ãªGGUFãƒ•ã‚¡ã‚¤ãƒ«"}
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Š
                metadata = self._read_metadata(f, header['metadata_count'])
                
                # MoEé–¢é€£æƒ…å ±æŠ½å‡º
                moe_info = self._extract_moe_info(metadata)
                
                # ãƒ†ãƒ³ã‚½ãƒ«æƒ…å ±èª­ã¿å–ã‚Š
                tensors_info = self._read_tensors_info(f, header['tensor_count'])
                
                # ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆé‡å­åŒ–ã‚¿ã‚¤ãƒ—åˆ†æ
                expert_analysis = self._analyze_expert_quantization(tensors_info, moe_info)
                
                return {
                    "status": "success",
                    "is_moe": moe_info.get("expert_count", 0) > 1,
                    "expert_count": moe_info.get("expert_count", 0),
                    "expert_used_count": moe_info.get("expert_used_count", 0),
                    "architecture": moe_info.get("architecture", "unknown"),
                    "expert_analysis": expert_analysis,
                    "needs_fix": expert_analysis.get("needs_fix", False),
                    "recommendation": expert_analysis.get("recommendation", "")
                }
                
        except Exception as e:
            logger.error(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {"status": "error", "message": str(e)}
    
    def _read_header(self, f) -> Optional[Dict]:
        """GGUFãƒ˜ãƒƒãƒ€ãƒ¼èª­ã¿å–ã‚Š"""
        # ãƒã‚¸ãƒƒã‚¯ç¢ºèª
        magic = f.read(4)
        if magic != GGUF_MAGIC:
            return None
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³
        version = struct.unpack('<I', f.read(4))[0]
        
        # ãƒ†ãƒ³ã‚½ãƒ«æ•°
        tensor_count = struct.unpack('<Q', f.read(8))[0]
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ•°
        metadata_count = struct.unpack('<Q', f.read(8))[0]
        
        return {
            'version': version,
            'tensor_count': tensor_count,
            'metadata_count': metadata_count
        }
    
    def _read_metadata(self, f, metadata_count: int) -> Dict[str, Any]:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Š"""
        metadata = {}
        
        for i in range(metadata_count):
            # ã‚­ãƒ¼èª­ã¿å–ã‚Š
            key_len = struct.unpack('<Q', f.read(8))[0]
            key = f.read(key_len).decode('utf-8')
            
            # å€¤èª­ã¿å–ã‚Š
            value = self._read_value(f)
            metadata[key] = value
        
        return metadata
    
    def _read_value(self, f):
        """å€¤èª­ã¿å–ã‚Š"""
        value_type = struct.unpack('<I', f.read(4))[0]
        
        if value_type == GGUF_TYPE_STRING:
            str_len = struct.unpack('<Q', f.read(8))[0]
            return f.read(str_len).decode('utf-8')
        elif value_type == GGUF_TYPE_ARRAY:
            array_type = struct.unpack('<I', f.read(4))[0]
            array_len = struct.unpack('<Q', f.read(8))[0]
            
            array_values = []
            for _ in range(array_len):
                if array_type == GGUF_TYPE_STRING:
                    str_len = struct.unpack('<Q', f.read(8))[0]
                    array_values.append(f.read(str_len).decode('utf-8'))
                else:
                    # ä»–ã®å‹ã¯ç°¡ç•¥åŒ–
                    f.read(self.type_sizes.get(array_type, 4))
                    array_values.append(None)
            
            return array_values
        elif value_type in self.type_sizes:
            size = self.type_sizes[value_type]
            data = f.read(size)
            
            if value_type == GGUF_TYPE_UINT32:
                return struct.unpack('<I', data)[0]
            elif value_type == GGUF_TYPE_UINT64:
                return struct.unpack('<Q', data)[0]
            elif value_type == GGUF_TYPE_FLOAT32:
                return struct.unpack('<f', data)[0]
            else:
                return data
        else:
            # ä¸æ˜ãªå‹
            return None
    
    def _extract_moe_info(self, metadata: Dict) -> Dict[str, Any]:
        """MoEæƒ…å ±æŠ½å‡º"""
        moe_info = {}
        
        for key in MOE_METADATA_KEYS:
            if key in metadata:
                if 'expert_count' in key:
                    moe_info['expert_count'] = metadata[key]
                elif 'expert_used_count' in key:
                    moe_info['expert_used_count'] = metadata[key]
                elif 'architecture' in key:
                    moe_info['architecture'] = metadata[key]
        
        return moe_info
    
    def _read_tensors_info(self, f, tensor_count: int) -> List[Dict]:
        """ãƒ†ãƒ³ã‚½ãƒ«æƒ…å ±èª­ã¿å–ã‚Š"""
        tensors = []
        
        for i in range(tensor_count):
            # ãƒ†ãƒ³ã‚½ãƒ«å
            name_len = struct.unpack('<Q', f.read(8))[0]
            name = f.read(name_len).decode('utf-8')
            
            # æ¬¡å…ƒæ•°
            n_dims = struct.unpack('<I', f.read(4))[0]
            
            # å½¢çŠ¶
            shape = []
            for _ in range(n_dims):
                shape.append(struct.unpack('<Q', f.read(8))[0])
            
            # ãƒ‡ãƒ¼ã‚¿å‹
            dtype = struct.unpack('<I', f.read(4))[0]
            
            # ã‚ªãƒ•ã‚»ãƒƒãƒˆ
            offset = struct.unpack('<Q', f.read(8))[0]
            
            tensors.append({
                'name': name,
                'shape': shape,
                'dtype': dtype,
                'offset': offset
            })
        
        return tensors
    
    def _analyze_expert_quantization(self, tensors_info: List[Dict], moe_info: Dict) -> Dict[str, Any]:
        """ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆé‡å­åŒ–åˆ†æ"""
        if not moe_info.get("expert_count", 0) > 1:
            return {"needs_fix": False, "recommendation": "MoEãƒ¢ãƒ‡ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“"}
        
        # ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆé–¢é€£ãƒ†ãƒ³ã‚µãƒ¼ã‚’ç‰¹å®š
        expert_tensors = []
        for tensor in tensors_info:
            name = tensor['name']
            if any(expert_keyword in name for expert_keyword in [
                'ffn_gate_inp', 'feed_forward', 'mlp', 'expert'
            ]):
                expert_tensors.append(tensor)
        
        if not expert_tensors:
            return {"needs_fix": False, "recommendation": "ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãƒ†ãƒ³ã‚µãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        # é‡å­åŒ–ã‚¿ã‚¤ãƒ—ã®åˆ†å¸ƒã‚’èª¿ã¹ã‚‹
        dtype_counts = {}
        for tensor in expert_tensors:
            dtype = tensor['dtype']
            dtype_counts[dtype] = dtype_counts.get(dtype, 0) + 1
        
        # æœ€ã‚‚ä¸€èˆ¬çš„ãªé‡å­åŒ–ã‚¿ã‚¤ãƒ—ã‚’æ±ºå®š
        most_common_dtype = max(dtype_counts, key=dtype_counts.get)
        
        # ä¸ä¸€è‡´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        has_mismatch = len(dtype_counts) > 1
        
        result = {
            "needs_fix": has_mismatch,
            "expert_tensors_count": len(expert_tensors),
            "dtype_distribution": dtype_counts,
            "most_common_dtype": most_common_dtype,
            "mismatch_count": sum(1 for dtype in dtype_counts if dtype != most_common_dtype)
        }
        
        if has_mismatch:
            result["recommendation"] = f"å…¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’é‡å­åŒ–ã‚¿ã‚¤ãƒ— {most_common_dtype} ã«çµ±ä¸€ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨"
        else:
            result["recommendation"] = "é‡å­åŒ–ã‚¿ã‚¤ãƒ—ã¯çµ±ä¸€ã•ã‚Œã¦ã„ã¾ã™"
        
        return result
    
    def fix_moe_quantization(self, input_path: str, output_path: str = None) -> bool:
        """MoEé‡å­åŒ–ä¿®å¾©"""
        logger.info(f"ğŸ”§ MoEé‡å­åŒ–ä¿®å¾©é–‹å§‹: {input_path}")
        
        # åˆ†æå®Ÿè¡Œ
        analysis = self.analyze_moe_model(input_path)
        
        if analysis["status"] != "success":
            logger.error(f"âŒ åˆ†æå¤±æ•—: {analysis.get('message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
            return False
        
        if not analysis["needs_fix"]:
            logger.info(f"âœ… ä¿®å¾©ä¸è¦: {analysis['recommendation']}")
            return True
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_path = self.create_backup(input_path)
        
        # å‡ºåŠ›ãƒ‘ã‚¹æ±ºå®š
        if output_path is None:
            output_path = input_path.replace('.gguf', '_moe_fixed.gguf')
        
        try:
            # ä¿®å¾©å®Ÿè¡Œ
            success = self._perform_moe_fix(input_path, output_path, analysis)
            
            if success:
                logger.info(f"âœ… MoEä¿®å¾©å®Œäº†: {output_path}")
                return True
            else:
                logger.error(f"âŒ MoEä¿®å¾©å¤±æ•—")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _perform_moe_fix(self, input_path: str, output_path: str, analysis: Dict) -> bool:
        """å®Ÿéš›ã®MoEä¿®å¾©å‡¦ç†"""
        target_dtype = analysis["expert_analysis"]["most_common_dtype"]
        
        logger.info(f"ğŸ”§ é‡å­åŒ–ã‚¿ã‚¤ãƒ—ã‚’ {target_dtype} ã«çµ±ä¸€ä¸­...")
        
        with open(input_path, 'rb') as src, open(output_path, 'wb') as dst:
            # ãƒ˜ãƒƒãƒ€ãƒ¼èª­ã¿å–ã‚Šãƒ»æ›¸ãè¾¼ã¿
            header_data = src.read(24)  # magic + version + tensor_count + metadata_count
            dst.write(header_data)
            
            header = struct.unpack('<4sIQQ', header_data)
            tensor_count = header[2]
            metadata_count = header[3]
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼
            metadata_start = src.tell()
            metadata_size = self._calculate_metadata_size(src, metadata_count)
            src.seek(metadata_start)
            metadata_data = src.read(metadata_size)
            dst.write(metadata_data)
            
            # ãƒ†ãƒ³ã‚µãƒ¼æƒ…å ±éƒ¨åˆ†ã®ä¿®å¾©
            tensors_start = src.tell()
            
            for i in range(tensor_count):
                tensor_start_pos = src.tell()
                
                # ãƒ†ãƒ³ã‚µãƒ¼å
                name_len = struct.unpack('<Q', src.read(8))[0]
                name = src.read(name_len).decode('utf-8')
                
                # æ¬¡å…ƒæ•°
                n_dims = struct.unpack('<I', src.read(4))[0]
                
                # å½¢çŠ¶
                shape = []
                for _ in range(n_dims):
                    shape.append(struct.unpack('<Q', src.read(8))[0])
                
                # ãƒ‡ãƒ¼ã‚¿å‹
                dtype = struct.unpack('<I', src.read(4))[0]
                
                # ã‚ªãƒ•ã‚»ãƒƒãƒˆ
                offset = struct.unpack('<Q', src.read(8))[0]
                
                # ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆé–¢é€£ãƒ†ãƒ³ã‚µãƒ¼ã®å ´åˆã¯é‡å­åŒ–ã‚¿ã‚¤ãƒ—ã‚’ä¿®æ­£
                is_expert_tensor = any(expert_keyword in name for expert_keyword in [
                    'ffn_gate_inp', 'feed_forward', 'mlp', 'expert'
                ])
                
                if is_expert_tensor and dtype != target_dtype:
                    logger.info(f"   ğŸ“ ä¿®æ­£: {name} ({dtype} -> {target_dtype})")
                    dtype = target_dtype
                
                # ä¿®æ­£ã•ã‚ŒãŸãƒ†ãƒ³ã‚µãƒ¼æƒ…å ±ã‚’æ›¸ãè¾¼ã¿
                dst.write(struct.pack('<Q', name_len))
                dst.write(name.encode('utf-8'))
                dst.write(struct.pack('<I', n_dims))
                for dim in shape:
                    dst.write(struct.pack('<Q', dim))
                dst.write(struct.pack('<I', dtype))
                dst.write(struct.pack('<Q', offset))
            
            # ãƒ†ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼
            remaining_data = src.read()
            dst.write(remaining_data)
        
        return True
    
    def _calculate_metadata_size(self, f, metadata_count: int) -> int:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºè¨ˆç®—"""
        start_pos = f.tell()
        
        for i in range(metadata_count):
            # ã‚­ãƒ¼
            key_len = struct.unpack('<Q', f.read(8))[0]
            f.read(key_len)
            
            # å€¤
            self._skip_value(f)
        
        end_pos = f.tell()
        f.seek(start_pos)
        
        return end_pos - start_pos
    
    def _skip_value(self, f):
        """å€¤ã‚’ã‚¹ã‚­ãƒƒãƒ—"""
        value_type = struct.unpack('<I', f.read(4))[0]
        
        if value_type == GGUF_TYPE_STRING:
            str_len = struct.unpack('<Q', f.read(8))[0]
            f.read(str_len)
        elif value_type == GGUF_TYPE_ARRAY:
            array_type = struct.unpack('<I', f.read(4))[0]
            array_len = struct.unpack('<Q', f.read(8))[0]
            
            for _ in range(array_len):
                if array_type == GGUF_TYPE_STRING:
                    str_len = struct.unpack('<Q', f.read(8))[0]
                    f.read(str_len)
                else:
                    f.read(self.type_sizes.get(array_type, 4))
        elif value_type in self.type_sizes:
            f.read(self.type_sizes[value_type])
    
    def print_analysis_report(self, analysis: Dict):
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ“Š MoEãƒ¢ãƒ‡ãƒ«åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*60)
        
        if analysis["status"] != "success":
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {analysis['message']}")
            return
        
        print(f"ğŸ¤– ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: {analysis['architecture']}")
        print(f"ğŸ§  MoEãƒ¢ãƒ‡ãƒ«: {'ã¯ã„' if analysis['is_moe'] else 'ã„ã„ãˆ'}")
        
        if analysis['is_moe']:
            print(f"ğŸ‘¥ ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°: {analysis['expert_count']}")
            print(f"ğŸ¯ ä½¿ç”¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°: {analysis['expert_used_count']}")
            
            expert_analysis = analysis["expert_analysis"]
            print(f"ğŸ”§ ä¿®å¾©å¿…è¦: {'ã¯ã„' if analysis['needs_fix'] else 'ã„ã„ãˆ'}")
            print(f"ğŸ“Š ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãƒ†ãƒ³ã‚µãƒ¼æ•°: {expert_analysis['expert_tensors_count']}")
            
            print("\nğŸ“ˆ é‡å­åŒ–ã‚¿ã‚¤ãƒ—åˆ†å¸ƒ:")
            for dtype, count in expert_analysis["dtype_distribution"].items():
                print(f"   ã‚¿ã‚¤ãƒ— {dtype}: {count}å€‹")
            
            print(f"\nğŸ’¡ æ¨å¥¨äº‹é …: {expert_analysis['recommendation']}")
        
        print("="*60)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='llama.cpp MoEä¿®å¾©ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('input', help='å…¥åŠ›GGUFãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('-o', '--output', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰')
    parser.add_argument('-a', '--analyze-only', action='store_true', help='åˆ†æã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--backup-dir', default='emergency_backups', help='ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input):
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.input}")
        sys.exit(1)
    
    # ä¿®å¾©ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    fixer = LlamaCppMoEFixer(backup_dir=args.backup_dir)
    
    # åˆ†æå®Ÿè¡Œ
    analysis = fixer.analyze_moe_model(args.input)
    fixer.print_analysis_report(analysis)
    
    if args.analyze_only:
        print("\nâœ… åˆ†æå®Œäº†")
        return
    
    if analysis["status"] == "success" and analysis["needs_fix"]:
        print(f"\nğŸ”§ ä¿®å¾©ã‚’é–‹å§‹ã—ã¾ã™...")
        success = fixer.fix_moe_quantization(args.input, args.output)
        
        if success:
            print(f"\nâœ… ä¿®å¾©ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        else:
            print(f"\nâŒ ä¿®å¾©ã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
    else:
        print(f"\nâœ… ä¿®å¾©ã¯ä¸è¦ã§ã™")

if __name__ == "__main__":
    main() 