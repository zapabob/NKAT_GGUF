#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NKAT-Kobold.cppçµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¬ã‚·ãƒ”ã«åŸºã¥ãNKATæ‹¡å¼µå®Ÿè£…
"""

import os
import sys
import json
import subprocess
import shutil
from pathlib import Path
import logging
from tqdm import tqdm
import torch

# ãƒ­ã‚°è¨­å®šï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('nkat_kobold_integration.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class NKATKoboldIntegrator:
    def __init__(self):
        self.project_root = Path(".")
        self.llama_cpp_dir = self.project_root / "llama.cpp"
        self.ggml_src_dir = self.llama_cpp_dir / "ggml" / "src"
        self.nkat_extensions = {
            "nkat_star_gemm": False,
            "nkat_theta_path": False,
            "nkat_decay": False,
            "backend_selector": False
        }
        
    def check_cuda_availability(self):
        """CUDAç’°å¢ƒã¨RTX 3080ã®ç¢ºèª"""
        try:
            if not torch.cuda.is_available():
                logger.warning("âš ï¸  CUDA ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                return False
                
            device_count = torch.cuda.device_count()
            logger.info(f"ğŸ¯ CUDA ãƒ‡ãƒã‚¤ã‚¹æ•°: {device_count}")
            
            for i in range(device_count):
                props = torch.cuda.get_device_properties(i)
                logger.info(f"   GPU {i}: {props.name} (ãƒ¡ãƒ¢ãƒª: {props.total_memory / 1024**3:.1f} GB)")
                
                # RTX 3080 æ¤œå‡º
                if "3080" in props.name:
                    logger.info("ğŸ”¥ RTX 3080 æ¤œå‡ºï¼æœ€é©åŒ–ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã™")
                    return True
                    
            return True
            
        except Exception as e:
            logger.error(f"âŒ CUDA ãƒã‚§ãƒƒã‚¯å¤±æ•—: {e}")
            return False
    
    def check_nkat_integration_status(self):
        """ç¾åœ¨ã®NKATçµ±åˆçŠ¶æ³ã‚’ç¢ºèª"""
        logger.info("ğŸ“‹ NKATçµ±åˆçŠ¶æ³ç¢ºèªä¸­...")
        
        # ggml.c ã§ã®NKATå®Ÿè£…ãƒã‚§ãƒƒã‚¯
        ggml_c_path = self.ggml_src_dir / "ggml.c"
        if ggml_c_path.exists():
            with open(ggml_c_path, 'r', encoding='utf-8') as f:
                content = f.read()
                if "GGML_OP_NKAT_STAR_GEMM" in content:
                    self.nkat_extensions["nkat_star_gemm"] = True
                    logger.info("âœ… NKAT STAR GEMM å®Ÿè£…æ¸ˆã¿")
                else:
                    logger.info("â³ NKAT STAR GEMM æœªå®Ÿè£…")
        
        # backend_selector.py ãƒã‚§ãƒƒã‚¯ï¼ˆkobold.cppç”¨ï¼‰
        backend_selector_path = self.project_root / "backend_selector.py"
        if backend_selector_path.exists():
            self.nkat_extensions["backend_selector"] = True
            logger.info("âœ… Backend Selector å­˜åœ¨")
        else:
            logger.info("â³ Backend Selector æœªä½œæˆ")
            
        return any(self.nkat_extensions.values())
    
    def create_nkat_backend_selector(self):
        """Kobold.cppç”¨ã®NKATãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ä½œæˆ"""
        logger.info("ğŸ› ï¸  NKAT Backend Selector ä½œæˆä¸­...")
        
        backend_selector_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NKAT-Kobold.cpp Backend Selector
ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¬ã‚·ãƒ”ã«åŸºã¥ãæœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
"""

import os
import json
import logging
from pathlib import Path

class NKATBackendSelector:
    def __init__(self):
        self.config = {
            "nkat_star_gemm": True,
            "cuda_optimization": True,
            "rtx_3080_optimization": True,
            "rope_scaling": "low",
            "mirostat_2": True,
            "default_settings": {
                "threads": 12,
                "parallel": 4,
                "context": 4096,
                "gpu_layers": 35,  # Q4_K_M 7Bç”¨
                "cuda_f16": True,
                "mirostat": 2,
                "mirostat_lr": 0.6
            }
        }
    
    def get_optimal_gpu_layers(self, model_size, quantization="Q4_K_M"):
        """ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨é‡å­åŒ–ã«åŸºã¥ãæœ€é©GPUå±¤æ•°"""
        optimization_table = {
            "7B": {"Q4_K_M": 35, "Q6_K": 30, "Q8_0": 25, "Q4_0": 40},
            "13B": {"Q4_K_M": 28, "Q6_K": 25, "Q8_0": 20, "Q4_0": 32},
            "30B": {"Q4_K_M": 15, "Q6_K": 12, "Q8_0": 10, "Q4_0": 18},
            "70B": {"Q4_K_M": 8, "Q6_K": 6, "Q8_0": 5, "Q4_0": 10}
        }
        
        return optimization_table.get(model_size, {}).get(quantization, 30)
    
    def get_rtx_3080_optimization(self):
        """RTX 3080å°‚ç”¨æœ€é©åŒ–è¨­å®š"""
        return {
            "cuda_architectures": "86",
            "tensor_cores": True,
            "memory_optimization": True,
            "max_vram_usage": "9.5GB",  # 10GBä¸­9.5GBä½¿ç”¨
            "batch_size_optimization": True
        }
    
    def generate_kobold_command(self, model_path, custom_settings=None):
        """æœ€é©åŒ–ã•ã‚ŒãŸKobold.cppã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ"""
        settings = self.config["default_settings"].copy()
        if custom_settings:
            settings.update(custom_settings)
        
        # ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºè‡ªå‹•æ¤œå‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
        model_name = Path(model_path).name.lower()
        if "7b" in model_name:
            settings["gpu_layers"] = self.get_optimal_gpu_layers("7B")
        elif "13b" in model_name:
            settings["gpu_layers"] = self.get_optimal_gpu_layers("13B")
        
        command_parts = [
            "python koboldcpp.py",
            f"--model \\"{model_path}\\"",
            f"--threads {settings['threads']}",
            f"--parallel {settings['parallel']}",
            f"--context {settings['context']}",
            f"--gpu-layers {settings['gpu_layers']}",
            "--rope-scaling low",
            "--cuda-f16",
            f"--mirostat {settings['mirostat']}",
            f"--mirostat-lr {settings['mirostat_lr']}"
        ]
        
        # NKATæ‹¡å¼µãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå®Ÿè£…æ¸ˆã¿ã®å ´åˆï¼‰
        if self.config.get("nkat_star_gemm", False):
            command_parts.extend([
                "--nkat-theta-path theta_rank4.bin",
                "--nkat-decay 0.97"
            ])
        
        return " ".join(command_parts)
    
    def save_config(self, filepath="nkat_kobold_config.json"):
        """è¨­å®šã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)

if __name__ == "__main__":
    selector = NKATBackendSelector()
    
    # è¨­å®šä¿å­˜
    selector.save_config()
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ
    sample_command = selector.generate_kobold_command(
        "models/llama-7b-q4_k_m.gguf"
    )
    
    print("ğŸ”¥ NKAT-Kobold.cppæœ€é©åŒ–ã‚³ãƒãƒ³ãƒ‰:")
    print(sample_command)
    print()
    print("ğŸ“‹ RTX 3080æœ€é©åŒ–è¨­å®š:")
    rtx_settings = selector.get_rtx_3080_optimization()
    for key, value in rtx_settings.items():
        print(f"   {key}: {value}")
'''
        
        with open("backend_selector.py", 'w', encoding='utf-8') as f:
            f.write(backend_selector_content)
        
        logger.info("âœ… Backend Selector ä½œæˆå®Œäº†")
        self.nkat_extensions["backend_selector"] = True
    
    def create_nkat_theta_generator(self):
        """NKAT Theta ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ"""
        logger.info("ğŸ§® NKAT Theta ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
        
        try:
            # ãƒ€ãƒŸãƒ¼ã®theta_rank4.binãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ãªå€¤ã‚’ä½¿ç”¨ï¼‰
            import numpy as np
            
            theta_data = {
                "rank": 4,
                "decay": 0.97,
                "temperature": 0.7,
                "nkat_coefficients": np.random.randn(4, 4096).astype(np.float16)
            }
            
            # ãƒã‚¤ãƒŠãƒªå½¢å¼ã§ä¿å­˜
            np.savez_compressed("theta_rank4.npz", **theta_data)
            
            # .binãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ã‚‚ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆkobold.cppäº’æ›ç”¨ï¼‰
            with open("theta_rank4.bin", 'wb') as f:
                # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
                f.write(b"NKAT")  # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼
                f.write((4).to_bytes(4, 'little'))  # rank
                f.write(len(theta_data["nkat_coefficients"].tobytes()).to_bytes(4, 'little'))
                # ãƒ‡ãƒ¼ã‚¿
                f.write(theta_data["nkat_coefficients"].tobytes())
            
            logger.info("âœ… Theta ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†")
            self.nkat_extensions["nkat_theta_path"] = True
            
        except Exception as e:
            logger.error(f"âŒ Theta ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆå¤±æ•—: {e}")
    
    def create_performance_monitor(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ"""
        logger.info("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼ä½œæˆä¸­...")
        
        monitor_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NKAT-Kobold.cpp ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼
"""

import time
import psutil
import subprocess
import json
from datetime import datetime

class NKATPerformanceMonitor:
    def __init__(self):
        self.start_time = None
        self.metrics = []
    
    def start_monitoring(self):
        """ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°é–‹å§‹"""
        self.start_time = time.time()
        print("ğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°é–‹å§‹")
    
    def get_gpu_stats(self):
        """GPUçµ±è¨ˆå–å¾—"""
        try:
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu", 
                 "--format=csv,noheader,nounits"],
                capture_output=True, text=True, check=True
            )
            gpu_data = result.stdout.strip().split(", ")
            return {
                "gpu_utilization": float(gpu_data[0]),
                "memory_used": float(gpu_data[1]),
                "memory_total": float(gpu_data[2]),
                "temperature": float(gpu_data[3])
            }
        except:
            return None
    
    def log_metrics(self, tokens_per_second=None):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²"""
        cpu_percent = psutil.cpu_percent()
        memory = psutil.virtual_memory()
        gpu_stats = self.get_gpu_stats()
        
        metric = {
            "timestamp": datetime.now().isoformat(),
            "cpu_percent": cpu_percent,
            "memory_percent": memory.percent,
            "tokens_per_second": tokens_per_second
        }
        
        if gpu_stats:
            metric.update(gpu_stats)
        
        self.metrics.append(metric)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
        print(f"ğŸ“Š CPU: {cpu_percent:.1f}% | RAM: {memory.percent:.1f}% | " +
              f"GPU: {gpu_stats['gpu_utilization']:.1f}% | " +
              f"VRAM: {gpu_stats['memory_used']:.0f}/{gpu_stats['memory_total']:.0f}MB | " +
              f"Tok/s: {tokens_per_second or 'N/A'}")
    
    def save_report(self, filename="nkat_performance_report.json"):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.metrics, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {filename}")

if __name__ == "__main__":
    monitor = NKATPerformanceMonitor()
    monitor.start_monitoring()
    
    try:
        while True:
            monitor.log_metrics()
            time.sleep(2)
    except KeyboardInterrupt:
        monitor.save_report()
        print("\\nâœ… ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°çµ‚äº†")
'''
        
        with open("nkat_performance_monitor.py", 'w', encoding='utf-8') as f:
            f.write(monitor_content)
        
        logger.info("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼ä½œæˆå®Œäº†")
    
    def run_integration(self):
        """NKAT-Kobold.cppçµ±åˆå®Ÿè¡Œ"""
        logger.info("ğŸš€ NKAT-Kobold.cppçµ±åˆé–‹å§‹...")
        
        # CUDAç¢ºèª
        if not self.check_cuda_availability():
            logger.warning("âš ï¸  CUDAæœªç¢ºèªã®ãŸã‚ä¸€éƒ¨æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¾ã™")
        
        # ç¾åœ¨ã®çµ±åˆçŠ¶æ³ç¢ºèª
        self.check_nkat_integration_status()
        
        with tqdm(total=4, desc="NKATçµ±åˆé€²è¡Œä¸­") as pbar:
            # Backend Selectorä½œæˆ
            if not self.nkat_extensions["backend_selector"]:
                self.create_nkat_backend_selector()
            pbar.update(1)
            
            # Theta ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆ
            if not self.nkat_extensions["nkat_theta_path"]:
                self.create_nkat_theta_generator()
            pbar.update(1)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼ä½œæˆ
            self.create_performance_monitor()
            pbar.update(1)
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æœ€çµ‚åŒ–
            self.finalize_configuration()
            pbar.update(1)
        
        logger.info("ğŸ‰ NKAT-Kobold.cppçµ±åˆå®Œäº†ï¼")
        self.print_usage_instructions()
    
    def finalize_configuration(self):
        """æœ€çµ‚è¨­å®š"""
        config = {
            "nkat_kobold_integration": {
                "version": "1.0",
                "rtx_3080_optimized": True,
                "extensions": self.nkat_extensions,
                "recommended_models": [
                    "llama-7b-q4_k_m.gguf",
                    "llama-13b-q4_k_m.gguf",
                    "llama-7b-q6_k.gguf"
                ],
                "performance_targets": {
                    "tokens_per_second": "45+ (7B Q4_K_M)",
                    "perplexity_improvement": "-4%",
                    "vram_usage": "< 9.5GB"
                }
            }
        }
        
        with open("nkat_kobold_config_final.json", 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def print_usage_instructions(self):
        """ä½¿ç”¨æ–¹æ³•è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ¯ NKAT-Kobold.cpp ä½¿ç”¨æ–¹æ³•")
        print("="*60)
        print()
        print("1ï¸âƒ£ æœ€é©åŒ–ãƒ“ãƒ«ãƒ‰å®Ÿè¡Œ:")
        print("   py -3 -c \"exec(open('setup_nkat_kobold_integration.py').read())\"")
        print("   .\\build_nkat_kobold_optimized.ps1")
        print()
        print("2ï¸âƒ£ Backend Selectorä½¿ç”¨:")
        print("   py -3 backend_selector.py")
        print()
        print("3ï¸âƒ£ æ¨å¥¨å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ (7B Q4_K_M):")
        print("   python koboldcpp.py --model models/llama-7b-q4_k_m.gguf \\")
        print("     --threads 12 --parallel 4 --context 4096 \\")
        print("     --gpu-layers 35 --cuda-f16 --rope-scaling low \\")
        print("     --mirostat 2 --mirostat-lr 0.6")
        print()
        print("4ï¸âƒ£ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°:")
        print("   py -3 nkat_performance_monitor.py")
        print()
        print("ğŸ’¡ ãƒ¬ã‚·ãƒ”ã®ãƒã‚¤ãƒ³ãƒˆ:")
        print("   âœ… Q4_K_M: é€Ÿåº¦ãƒ»å“è³ªãƒ»VRAMæœ€é©ãƒãƒ©ãƒ³ã‚¹")
        print("   âœ… gpu_layers=35: RTX 3080 (10GB) æ¨å¥¨")  
        print("   âœ… threads=12: ç‰©ç†ã‚³ã‚¢æ•°æœ€é©åŒ–")
        print("   âœ… mirostat 2: é«˜å“è³ªå‡ºåŠ›åˆ¶å¾¡")
        print("="*60)

if __name__ == "__main__":
    integrator = NKATKoboldIntegrator()
    integrator.run_integration() 