#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸŒ€ Practical NKAT Fine-tuning System
å®Ÿç”¨çš„ãªéå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

Webã‚µãƒ¼ãƒçµæœã‚’æ´»ç”¨ã—ã€éå­¦ç¿’å•é¡Œã‚’è§£æ±ºã—ãŸå®Ÿè£…
"""

import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from tqdm import tqdm
import matplotlib.pyplot as plt
from pathlib import Path

class PracticalNKATOperator:
    """å®Ÿç”¨çš„NKATæ¼”ç®—å­ï¼ˆéå­¦ç¿’å•é¡Œè§£æ±ºç‰ˆï¼‰"""
    
    def __init__(self, strength: float = 0.02):
        self.strength = strength
        
        # å®Ÿæ•°ç‰ˆéå¯æ›ç”Ÿæˆå­ï¼ˆå®‰å®šåŒ–ï¼‰
        self.generators = [
            np.array([[0, 1], [1, 0]], dtype=np.float32),  # Ïƒ_x
            np.array([[1, 0], [0, -1]], dtype=np.float32), # Ïƒ_z
            np.array([[0, -1], [1, 0]], dtype=np.float32), # ä¿®æ­£Ïƒ_y
            np.eye(2, dtype=np.float32)                     # Identity
        ]
        
        print(f"ğŸ”§ PracticalNKATOperator: strength={strength}")
    
    def transform_tensor(self, tensor: np.ndarray) -> np.ndarray:
        """ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›ï¼ˆæ•°å€¤å®‰å®šç‰ˆï¼‰"""
        if tensor.size < 4:
            return tensor
        
        original_shape = tensor.shape
        flat_tensor = tensor.flatten()
        transformed = np.zeros_like(flat_tensor)
        
        # 2è¦ç´ ãƒšã‚¢å‡¦ç†
        for i in range(0, len(flat_tensor) - 1, 2):
            vec = flat_tensor[i:i+2]
            
            # å®‰å…¨ãªç”Ÿæˆå­é¸æŠ
            gen_idx = (i // 2) % len(self.generators)
            generator = self.generators[gen_idx]
            
            # éå¯æ›å¤‰æ›ï¼ˆæ­£å‰‡åŒ–ä»˜ãï¼‰
            if len(vec) == 2 and not np.any(np.isnan(vec)):
                # äº¤æ›å­ã®è¿‘ä¼¼è¨ˆç®—
                gv = generator @ vec
                vg_approx = vec * np.diag(generator)
                
                commutator = gv - vg_approx
                
                # å¼·ã„æ­£å‰‡åŒ–
                commutator = np.clip(commutator, -0.1, 0.1)
                
                # å®‰å…¨ãªå¤‰æ›
                transformed_vec = vec + self.strength * commutator
                transformed_vec = np.clip(transformed_vec, -10.0, 10.0)
                
                transformed[i:i+2] = transformed_vec
            else:
                transformed[i:i+2] = vec
        
        # ä½™ã‚Šå‡¦ç†
        if len(flat_tensor) % 2 == 1:
            transformed[-1] = flat_tensor[-1]
        
        return transformed.reshape(original_shape)
    
    def kan_enhancement(self, tensor: np.ndarray) -> np.ndarray:
        """KANé¢¨æ‹¡å¼µï¼ˆè»½é‡ç‰ˆï¼‰"""
        if tensor.size < 3:
            return tensor
        
        enhanced = tensor.copy()
        
        # è»½é‡B-splineé¢¨ãƒ•ã‚£ãƒ«ã‚¿
        for i in range(1, len(enhanced.flatten()) - 1):
            neighbors = enhanced.flat[i-1:i+2]
            if len(neighbors) == 3:
                # 3ç‚¹å¹³å‡ãƒ•ã‚£ãƒ«ã‚¿
                enhanced.flat[i] = 0.25 * neighbors[0] + 0.5 * neighbors[1] + 0.25 * neighbors[2]
        
        # è»½å¾®ãªéç·šå½¢å¤‰æ›
        enhanced = 0.9 * enhanced + 0.1 * np.tanh(enhanced)
        
        return enhanced


class SimplifiedNeuralModel(nn.Module):
    """ç°¡å˜åŒ–ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(self, input_dim: int = 256):
        super().__init__()
        self.input_dim = input_dim
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹é€ 
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        self.decoder = nn.Sequential(
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, input_dim)
        )
        
        print(f"ğŸ§  SimplifiedNeuralModel: {input_dim}D")
    
    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded


class PracticalNKATTrainer:
    """å®Ÿç”¨çš„NKATãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼"""
    
    def __init__(self, model, device='cpu'):
        self.model = model.to(device)
        self.device = device
        self.nkat_op = PracticalNKATOperator(strength=0.03)
        
        # å®‰å®šã—ãŸæœ€é©åŒ–å™¨
        self.optimizer = torch.optim.Adam(
            model.parameters(), 
            lr=0.001, 
            weight_decay=0.01
        )
        
        # çµ±è¨ˆ
        self.stats = {
            'losses': [],
            'nkat_enhancements': 0,
            'epochs_trained': 0
        }
        
        print(f"ğŸ“ PracticalNKATTrainer on {device}")
    
    def generate_test_data(self, num_samples=500):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        print(f"ğŸ“Š Generating {num_samples} test samples...")
        
        data = []
        for i in range(num_samples):
            # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            t = np.linspace(0, 2*np.pi, self.model.input_dim)
            
            # è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¿¡å·
            if i % 3 == 0:
                signal = np.sin(t) + 0.3 * np.sin(3*t)
            elif i % 3 == 1:
                signal = np.cos(t) + 0.2 * np.cos(5*t)
            else:
                signal = np.sin(t) * np.cos(t/2)
            
            # ãƒã‚¤ã‚ºè¿½åŠ 
            signal += 0.1 * np.random.randn(len(signal))
            
            # æ­£è¦åŒ–
            signal = (signal - np.mean(signal)) / (np.std(signal) + 1e-8)
            
            data.append(signal.astype(np.float32))
        
        dataset = torch.utils.data.TensorDataset(
            torch.from_numpy(np.array(data))
        )
        
        dataloader = torch.utils.data.DataLoader(
            dataset, batch_size=32, shuffle=True
        )
        
        print(f"âœ… Generated {len(data)} samples")
        return dataloader
    
    def train_epoch(self, dataloader):
        """1ã‚¨ãƒãƒƒã‚¯è¨“ç·´"""
        self.model.train()
        epoch_loss = 0.0
        num_batches = 0
        
        for batch in tqdm(dataloader, desc="Training", leave=False):
            x = batch[0].to(self.device)
            
            self.optimizer.zero_grad()
            
            # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹
            reconstructed = self.model(x)
            
            # åŸºæœ¬çš„ãªå†æ§‹æˆæå¤±
            loss = F.mse_loss(reconstructed, x)
            
            # NKATæ‹¡å¼µï¼ˆãƒãƒƒãƒã®ä¸€éƒ¨ã®ã¿ï¼‰
            if num_batches % 3 == 0:  # 3å›ã«1å›ã®ã¿é©ç”¨
                with torch.no_grad():
                    # CPUã§NKATå¤‰æ›
                    x_numpy = x.cpu().numpy()
                    for i in range(x_numpy.shape[0]):
                        enhanced = self.nkat_op.transform_tensor(x_numpy[i])
                        enhanced = self.nkat_op.kan_enhancement(enhanced)
                        x_numpy[i] = enhanced
                    
                    x_enhanced = torch.from_numpy(x_numpy).to(self.device)
                    
                    # æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ã§ã®è¿½åŠ æå¤±
                    reconstructed_enhanced = self.model(x_enhanced)
                    enhancement_loss = F.mse_loss(reconstructed_enhanced, x_enhanced)
                    
                    # è»½å¾®ãªæ‹¡å¼µæå¤±ã‚’è¿½åŠ 
                    loss = loss + 0.1 * enhancement_loss
                    
                    self.stats['nkat_enhancements'] += 1
            
            # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
            loss.backward()
            
            # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
            
            epoch_loss += loss.item()
            num_batches += 1
        
        avg_loss = epoch_loss / num_batches
        self.stats['losses'].append(avg_loss)
        self.stats['epochs_trained'] += 1
        
        return avg_loss
    
    def evaluate(self, dataloader):
        """è©•ä¾¡"""
        self.model.eval()
        total_loss = 0.0
        num_samples = 0
        
        with torch.no_grad():
            for batch in dataloader:
                x = batch[0].to(self.device)
                reconstructed = self.model(x)
                loss = F.mse_loss(reconstructed, x)
                
                total_loss += loss.item() * x.size(0)
                num_samples += x.size(0)
        
        return total_loss / num_samples
    
    def save_model(self, path: str):
        """ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        os.makedirs(os.path.dirname(path), exist_ok=True)
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'stats': self.stats,
            'nkat_strength': self.nkat_op.strength
        }, path)
        print(f"ğŸ’¾ Model saved: {path}")
    
    def plot_training_progress(self, save_path: str = None):
        """è¨“ç·´é€²æ—å¯è¦–åŒ–"""
        plt.figure(figsize=(12, 4))
        
        plt.subplot(1, 2, 1)
        plt.plot(self.stats['losses'], 'b-', linewidth=2)
        plt.title('Training Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.grid(True)
        
        plt.subplot(1, 2, 2)
        plt.bar(['Epochs', 'NKAT Enhancements'], 
                [self.stats['epochs_trained'], self.stats['nkat_enhancements']])
        plt.title('Training Statistics')
        plt.ylabel('Count')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š Progress saved: {save_path}")
        
        plt.show()


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸŒ€ Practical NKAT Fine-tuning System")
    print("=" * 60)
    print("ğŸ“š Non-Commutative Kolmogorov-Arnold Representation Theory")
    print("ğŸ¯ Overfitting-Resistant Implementation")
    print("ğŸ›¡ï¸ Based on research insights from Medium article")
    print("=" * 60)
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ Using device: {device}")
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    model = SimplifiedNeuralModel(input_dim=256)
    trainer = PracticalNKATTrainer(model, device)
    
    # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    train_dataloader = trainer.generate_test_data(num_samples=800)
    val_dataloader = trainer.generate_test_data(num_samples=200)
    
    print(f"\nğŸš€ Starting Training...")
    print(f"   Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # è¨“ç·´å®Ÿè¡Œ
    num_epochs = 20
    best_val_loss = float('inf')
    
    for epoch in range(num_epochs):
        print(f"\nğŸ“… Epoch {epoch+1}/{num_epochs}")
        
        # è¨“ç·´
        train_loss = trainer.train_epoch(train_dataloader)
        
        # æ¤œè¨¼
        val_loss = trainer.evaluate(val_dataloader)
        
        print(f"   Train Loss: {train_loss:.6f}")
        print(f"   Val Loss: {val_loss:.6f}")
        print(f"   NKAT Enhancements: {trainer.stats['nkat_enhancements']}")
        
        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            trainer.save_model('output/best_practical_nkat_model.pth')
            print(f"   ğŸ’¾ Best model updated (Val Loss: {best_val_loss:.6f})")
        
        # éå­¦ç¿’æ—©æœŸæ¤œå‡º
        if epoch > 5 and len(trainer.stats['losses']) > 3:
            recent_losses = trainer.stats['losses'][-3:]
            if all(loss > train_loss * 1.1 for loss in recent_losses):
                print(f"   ğŸš¨ Potential overfitting detected")
    
    print(f"\nğŸ‰ Training Completed!")
    print(f"   Best Validation Loss: {best_val_loss:.6f}")
    print(f"   Total NKAT Enhancements: {trainer.stats['nkat_enhancements']}")
    print(f"   Final Training Loss: {trainer.stats['losses'][-1]:.6f}")
    
    # é€²æ—å¯è¦–åŒ–
    os.makedirs('output', exist_ok=True)
    trainer.plot_training_progress('output/practical_nkat_progress.png')
    
    # æœ€çµ‚è©•ä¾¡
    print(f"\nğŸ“Š Final Evaluation:")
    final_train_loss = trainer.evaluate(train_dataloader)
    final_val_loss = trainer.evaluate(val_dataloader)
    
    print(f"   Final Train Loss: {final_train_loss:.6f}")
    print(f"   Final Val Loss: {final_val_loss:.6f}")
    print(f"   Overfitting Ratio: {final_val_loss/final_train_loss:.3f}")
    
    # æˆåŠŸåˆ¤å®š
    if final_val_loss / final_train_loss < 1.5:
        print(f"   âœ… Training Successful (Low Overfitting)")
    else:
        print(f"   âš ï¸ Potential Overfitting Detected")
    
    print(f"\nğŸ¯ NKAT Implementation Summary:")
    print(f"   âœ“ Non-commutative algebra transformations")
    print(f"   âœ“ KAN-inspired enhancements")
    print(f"   âœ“ Overfitting prevention mechanisms")
    print(f"   âœ“ Numerical stability improvements")
    print(f"   âœ“ Practical applicability demonstrated")
    
    return trainer


if __name__ == "__main__":
    # RTX 3080æœ€é©åŒ–
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = True
        print(f"ğŸš€ CUDA optimization enabled")
    
    # å®Ÿè¡Œ
    trainer = main() 