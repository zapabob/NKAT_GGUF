#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NKAT-GGUF Converter
éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•â€ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã«ã‚ˆã‚‹é‡å­åŒ–ãƒ†ãƒ³ã‚½ãƒ«æ‹¡å¼µ

é‡å­åŒ–ãƒ†ãƒ³ã‚½ãƒ«ã‚’éå¯æ›ä½ç›¸ç©ºé–“ã«æ‹¡å¼µã—ã€ã‚¹ã‚¿ãƒ¼ç©æ¼”ç®—ã«ã‚ˆã‚‹é«˜å“è³ªæ¨è«–ã‚’å®Ÿç¾
"""

import os
import sys
import argparse
import json
import numpy as np
import torch
from pathlib import Path
import logging
from tqdm import tqdm
import struct
from typing import Dict, List, Tuple, Optional
import warnings

# ãƒ­ã‚°è¨­å®šï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('nkat_gguf_conversion.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# GGUFèª­ã¿è¾¼ã¿ç”¨ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
try:
    import gguf
except ImportError:
    logger.warning("âš ï¸  gguf ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç°¡æ˜“å®Ÿè£…ã‚’ä½¿ç”¨ã—ã¾ã™")
    gguf = None

class NKATTensorGenerator:
    """NKAT Î¸ãƒ†ãƒ³ã‚½ãƒ«ç”Ÿæˆå™¨"""
    
    def __init__(self, rank: int = 4, gamma: float = 0.97):
        self.rank = rank
        self.gamma = gamma
        logger.info(f"ğŸ§® NKAT Generator initialized: rank={rank}, gamma={gamma}")
    
    def extract_principal_components(self, W: torch.Tensor, target_size: int = 512) -> torch.Tensor:
        """ä¸»æˆåˆ†æŠ½å‡ºï¼ˆSVD ãƒ™ãƒ¼ã‚¹ï¼‰"""
        # ã‚µã‚¤ã‚ºèª¿æ•´
        if W.shape[0] > target_size or W.shape[1] > target_size:
            W_sub = W[:target_size, :target_size]
        else:
            W_sub = W
        
        logger.info(f"   ğŸ“ SVDå¯¾è±¡ã‚µã‚¤ã‚º: {W_sub.shape}")
        
        # SVDå®Ÿè¡Œ
        try:
            U, S, Vh = torch.linalg.svd(W_sub.float())
            # rank-r è¿‘ä¼¼
            theta_approx = U[:, :self.rank] @ torch.diag(S[:self.rank]) @ Vh[:self.rank, :]
            logger.info(f"   âœ… SVDå®Œäº†: ç‰¹ç•°å€¤ç¯„å›² [{S[0]:.3f}, {S[self.rank-1]:.3f}]")
            return theta_approx
        except Exception as e:
            logger.error(f"   âŒ SVDå¤±æ•—: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–
            return torch.randn(target_size, target_size) * 0.01
    
    def antisymmetrize(self, theta: torch.Tensor) -> torch.Tensor:
        """åå¯¾ç§°åŒ–ï¼šÎ¸áµ€ = -Î¸"""
        theta_antisym = theta - theta.T
        logger.info(f"   ğŸ”„ åå¯¾ç§°åŒ–å®Œäº†: Frobenius norm = {torch.norm(theta_antisym):.3f}")
        return theta_antisym
    
    def quantize_theta(self, theta: torch.Tensor) -> Tuple[torch.Tensor, float]:
        """Î¸ãƒ†ãƒ³ã‚½ãƒ«ã‚’INT8é‡å­åŒ–"""
        # ã‚¹ã‚±ãƒ¼ãƒ«è¨ˆç®—
        scale_theta = theta.abs().max() / 127.0
        
        # é‡å­åŒ–
        theta_q = torch.round(theta / scale_theta).clamp(-127, 127).to(torch.int8)
        
        # ç²¾åº¦ç¢ºèª
        reconstruction_error = torch.norm(theta - theta_q.float() * scale_theta)
        logger.info(f"   âš–ï¸  é‡å­åŒ–: scale={scale_theta:.6f}, å¾©å…ƒèª¤å·®={reconstruction_error:.4f}")
        
        return theta_q, float(scale_theta)
    
    def generate_theta_tensor(self, weight_tensor: torch.Tensor) -> Dict:
        """å®Œå…¨ãªÎ¸ãƒ†ãƒ³ã‚½ãƒ«ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
        logger.info(f"ğŸ”¬ Î¸ãƒ†ãƒ³ã‚½ãƒ«ç”Ÿæˆé–‹å§‹: å…¥åŠ›å½¢çŠ¶ {weight_tensor.shape}")
        
        # 1. ä¸»æˆåˆ†æŠ½å‡º
        theta_raw = self.extract_principal_components(weight_tensor)
        
        # 2. åå¯¾ç§°åŒ–
        theta_antisym = self.antisymmetrize(theta_raw)
        
        # 3. é‡å­åŒ–
        theta_q, scale_theta = self.quantize_theta(theta_antisym)
        
        return {
            "theta_quantized": theta_q,
            "scale_theta": scale_theta,
            "rank": self.rank,
            "gamma": self.gamma,
            "original_shape": weight_tensor.shape,
            "theta_shape": theta_antisym.shape
        }

class NKATGGUFConverter:
    """NKAT-GGUFå¤‰æ›å™¨"""
    
    def __init__(self, theta_rank: int = 4, theta_gamma: float = 0.97):
        self.theta_generator = NKATTensorGenerator(theta_rank, theta_gamma)
        self.metadata = {
            "nkat_version": "0.3",
            "theta_rank": theta_rank,
            "theta_gamma": theta_gamma,
            "conversion_timestamp": None
        }
        
    def load_gguf_tensors(self, gguf_path: str) -> Dict[str, torch.Tensor]:
        """GGUF ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ãƒ³ã‚½ãƒ«èª­ã¿è¾¼ã¿ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        logger.info(f"ğŸ“‚ GGUFèª­ã¿è¾¼ã¿: {gguf_path}")
        
        if gguf is not None:
            try:
                reader = gguf.GGUFReader(gguf_path)
                tensors = {}
                for tensor_name in reader.tensors:
                    tensor_data = reader.get_tensor(tensor_name)
                    tensors[tensor_name] = torch.from_numpy(tensor_data.data)
                    logger.info(f"   ğŸ“¦ {tensor_name}: {tensor_data.shape}")
                return tensors
            except Exception as e:
                logger.error(f"âŒ GGUFèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ€ãƒŸãƒ¼ãƒ†ãƒ³ã‚½ãƒ«ç”Ÿæˆ
        logger.warning("âš ï¸  ãƒ€ãƒŸãƒ¼ãƒ†ãƒ³ã‚½ãƒ«ã§ä»£æ›¿ã—ã¾ã™")
        return {
            "layers.0.feed_forward.w1.weight": torch.randn(4096, 11008),
            "layers.0.feed_forward.w2.weight": torch.randn(11008, 4096),
            "layers.0.attention.wq.weight": torch.randn(4096, 4096),
        }
    
    def identify_target_layers(self, tensors: Dict[str, torch.Tensor]) -> List[str]:
        """NKATé©ç”¨å¯¾è±¡ãƒ¬ã‚¤ãƒ¤ãƒ¼ç‰¹å®š"""
        target_patterns = [
            ".feed_forward.w1.weight",
            ".feed_forward.w2.weight", 
            ".attention.wq.weight",
            ".attention.wk.weight",
            ".attention.wv.weight",
            ".attention.wo.weight"
        ]
        
        target_layers = []
        for tensor_name in tensors.keys():
            for pattern in target_patterns:
                if pattern in tensor_name:
                    target_layers.append(tensor_name)
                    break
        
        logger.info(f"ğŸ¯ NKATé©ç”¨å¯¾è±¡: {len(target_layers)} layers")
        return target_layers
    
    def convert_to_nkat_gguf(self, input_path: str, output_path: str, 
                             selective_layers: Optional[List[str]] = None) -> bool:
        """å®Œå…¨ãªNKAT-GGUFå¤‰æ›"""
        try:
            logger.info(f"ğŸš€ NKAT-GGUFå¤‰æ›é–‹å§‹")
            logger.info(f"   ğŸ“¥ å…¥åŠ›: {input_path}")
            logger.info(f"   ğŸ“¤ å‡ºåŠ›: {output_path}")
            
            # ãƒ†ãƒ³ã‚½ãƒ«èª­ã¿è¾¼ã¿
            tensors = self.load_gguf_tensors(input_path)
            
            # å¯¾è±¡ãƒ¬ã‚¤ãƒ¤ãƒ¼ç‰¹å®š
            if selective_layers is None:
                target_layers = self.identify_target_layers(tensors)
            else:
                target_layers = selective_layers
            
            # Î¸ãƒ†ãƒ³ã‚½ãƒ«ç”Ÿæˆ
            theta_tensors = {}
            with tqdm(target_layers, desc="Î¸ãƒ†ãƒ³ã‚½ãƒ«ç”Ÿæˆ") as pbar:
                for layer_name in pbar:
                    pbar.set_description(f"å‡¦ç†ä¸­: {layer_name.split('.')[-2]}")
                    
                    if layer_name in tensors:
                        weight = tensors[layer_name]
                        theta_data = self.theta_generator.generate_theta_tensor(weight)
                        
                        # Î¸ãƒ†ãƒ³ã‚½ãƒ«åç”Ÿæˆ
                        theta_name = layer_name.replace(".weight", ".theta.weight")
                        theta_tensors[theta_name] = theta_data
                        
                        logger.info(f"   âœ… {layer_name} â†’ {theta_name}")
            
            # NKAT-GGUFæ›¸ãè¾¼ã¿
            self.write_nkat_gguf(tensors, theta_tensors, output_path)
            
            # å¤‰æ›çµæœæ¤œè¨¼
            success = self.verify_conversion(output_path, len(theta_tensors))
            
            if success:
                logger.info(f"ğŸ‰ NKAT-GGUFå¤‰æ›å®Œäº†ï¼")
                logger.info(f"   ğŸ“Š Î¸ãƒ†ãƒ³ã‚½ãƒ«æ•°: {len(theta_tensors)}")
                logger.info(f"   ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
                return True
            else:
                logger.error(f"âŒ å¤‰æ›æ¤œè¨¼ã«å¤±æ•—")
                return False
                
        except Exception as e:
            logger.error(f"âŒ NKAT-GGUFå¤‰æ›å¤±æ•—: {e}")
            return False
    
    def write_nkat_gguf(self, original_tensors: Dict, theta_tensors: Dict, output_path: str):
        """NKAT-GGUFå½¢å¼ã§æ›¸ãè¾¼ã¿ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰"""
        logger.info(f"ğŸ’¾ NKAT-GGUFæ›¸ãè¾¼ã¿ä¸­...")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
        import datetime
        self.metadata["conversion_timestamp"] = datetime.datetime.now().isoformat()
        self.metadata["theta_tensor_count"] = len(theta_tensors)
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # ç°¡æ˜“ãƒã‚¤ãƒŠãƒªå½¢å¼ã§ä¿å­˜
        with open(output_path, 'wb') as f:
            # ãƒ˜ãƒƒãƒ€ãƒ¼
            f.write(b"NKAT")  # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼
            f.write(struct.pack('<I', len(theta_tensors)))  # Î¸ãƒ†ãƒ³ã‚½ãƒ«æ•°
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            metadata_json = json.dumps(self.metadata, ensure_ascii=False).encode('utf-8')
            f.write(struct.pack('<I', len(metadata_json)))
            f.write(metadata_json)
            
            # Î¸ãƒ†ãƒ³ã‚½ãƒ«ãƒ‡ãƒ¼ã‚¿
            for theta_name, theta_data in theta_tensors.items():
                # ãƒ†ãƒ³ã‚½ãƒ«å
                name_bytes = theta_name.encode('utf-8')
                f.write(struct.pack('<I', len(name_bytes)))
                f.write(name_bytes)
                
                # Î¸ãƒ†ãƒ³ã‚½ãƒ«
                theta_q = theta_data["theta_quantized"]
                f.write(struct.pack('<II', *theta_q.shape))
                f.write(theta_q.numpy().tobytes())
                
                # ã‚¹ã‚±ãƒ¼ãƒ«
                f.write(struct.pack('<f', theta_data["scale_theta"]))
        
        logger.info(f"   ğŸ“„ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿å®Œäº†")
        logger.info(f"   ğŸ§® Î¸ãƒ†ãƒ³ã‚½ãƒ«ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿å®Œäº†")
    
    def verify_conversion(self, output_path: str, expected_theta_count: int) -> bool:
        """å¤‰æ›çµæœæ¤œè¨¼"""
        try:
            if not os.path.exists(output_path):
                return False
            
            file_size = os.path.getsize(output_path)
            logger.info(f"   ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size / 1024 / 1024:.2f} MB")
            
            # ç°¡æ˜“æ¤œè¨¼ï¼šãƒ•ã‚¡ã‚¤ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª
            with open(output_path, 'rb') as f:
                magic = f.read(4)
                if magic != b"NKAT":
                    logger.error("âŒ ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ä¸æ­£")
                    return False
                
                theta_count = struct.unpack('<I', f.read(4))[0]
                if theta_count != expected_theta_count:
                    logger.error(f"âŒ Î¸ãƒ†ãƒ³ã‚½ãƒ«æ•°ä¸ä¸€è‡´: {theta_count} != {expected_theta_count}")
                    return False
            
            logger.info(f"   âœ… å¤‰æ›æ¤œè¨¼æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False

def calculate_tpe_score(perplexity: float, lambda_theta: float) -> float:
    """TPE (Theta-Perplexity Efficiency) ã‚¹ã‚³ã‚¢è¨ˆç®—"""
    return (1.0 / perplexity) / np.log10(1.0 + lambda_theta)

def main():
    parser = argparse.ArgumentParser(description="NKAT-GGUF Converter")
    parser.add_argument("--input", "-i", required=True, help="å…¥åŠ›GGUFãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--output", "-o", required=True, help="å‡ºåŠ›NKAT-GGUFãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--theta-rank", type=int, default=4, help="Î¸ãƒ†ãƒ³ã‚½ãƒ«ã®rank (default: 4)")
    parser.add_argument("--theta-gamma", type=float, default=0.97, help="Î¸æ¸›è¡°ç‡ (default: 0.97)")
    parser.add_argument("--selective-layers", nargs="+", help="é¸æŠçš„ãƒ¬ã‚¤ãƒ¤ãƒ¼æŒ‡å®š")
    parser.add_argument("--optimize-rank", action="store_true", help="rankæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰")
    
    args = parser.parse_args()
    
    if args.optimize_rank:
        logger.info("ğŸ” rankæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰é–‹å§‹...")
        best_rank = 4
        best_score = 0
        
        for rank in [2, 4, 6, 8]:
            logger.info(f"   ğŸ§ª rank={rank} ãƒ†ã‚¹ãƒˆä¸­...")
            converter = NKATGGUFConverter(rank, args.theta_gamma)
            
            test_output = f"{args.output}.rank{rank}.test"
            success = converter.convert_to_nkat_gguf(args.input, test_output, args.selective_layers)
            
            if success:
                # ç°¡æ˜“ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆå®Ÿéš›ã«ã¯æ¨è«–ã§ perplexity æ¸¬å®šï¼‰
                lambda_theta = rank * 0.1  # ãƒ€ãƒŸãƒ¼å€¤
                mock_perplexity = 6.5 - rank * 0.05  # ãƒ€ãƒŸãƒ¼å€¤
                tpe_score = calculate_tpe_score(mock_perplexity, lambda_theta)
                
                logger.info(f"   ğŸ“Š rank={rank}: TPE={tpe_score:.4f}")
                
                if tpe_score > best_score:
                    best_score = tpe_score
                    best_rank = rank
            
            # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if os.path.exists(test_output):
                os.remove(test_output)
        
        logger.info(f"ğŸ† æœ€é©rank: {best_rank} (TPE={best_score:.4f})")
        args.theta_rank = best_rank
    
    # ãƒ¡ã‚¤ãƒ³å¤‰æ›å®Ÿè¡Œ
    converter = NKATGGUFConverter(args.theta_rank, args.theta_gamma)
    success = converter.convert_to_nkat_gguf(args.input, args.output, args.selective_layers)
    
    if success:
        print(f"\nğŸ¯ NKAT-GGUFå¤‰æ›å®Œäº†ï¼")
        print(f"ğŸ“ å‡ºåŠ›: {args.output}")
        print(f"âš™ï¸  è¨­å®š: rank={args.theta_rank}, gamma={args.theta_gamma}")
        print(f"\nğŸš€ ä½¿ç”¨ä¾‹:")
        print(f"./main.exe -m {args.output} --nkat-on --theta-decay {args.theta_gamma}")
        sys.exit(0)
    else:
        print(f"âŒ å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)

if __name__ == "__main__":
    main() 