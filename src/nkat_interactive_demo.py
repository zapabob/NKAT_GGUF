#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NKAT Interactive Demo
å®Ÿæˆ¦ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆ & ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç’°å¢ƒ
"""

import os
import sys
import json
import time
import torch
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional
import logging
from tqdm import tqdm

# Import NKAT components
from nkat_inference_engine import NKATInferenceEngine
from nkat_gguf_converter import NKATGGUFConverter

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class NKATInteractiveDemo:
    """NKATå¯¾è©±å‹ãƒ‡ãƒ¢ç’°å¢ƒ"""
    
    def __init__(self):
        self.engine = None
        self.current_model = None
        self.performance_history = []
        self.test_prompts = [
            "Hello, how are you today?",
            "Write a Python function to calculate fibonacci numbers.",
            "Explain the concept of neural networks in simple terms.",
            "Tell me a short story about a robot learning to love.",
            "What are the advantages of quantum computing?"
        ]
    
    def show_banner(self):
        """é–‹å§‹ãƒãƒŠãƒ¼è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸš€ NKAT Interactive Demo & Chat Test Environment ğŸš€")
        print("="*60)
        print("ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š & ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´")
        print("ğŸ¤– å®Ÿæˆ¦ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆç’°å¢ƒ")
        print("ğŸ”§ RTX 3080 æœ€é©åŒ–æ¸ˆã¿")
        print("="*60 + "\n")
    
    def load_model(self, model_path: str) -> bool:
        """ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            logger.info(f"ğŸ“‚ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {model_path}")
            self.engine = NKATInferenceEngine(model_path, use_cuda=True)
            success = self.engine.load_model()
            
            if success:
                self.current_model = model_path
                logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
                return True
            else:
                logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def quick_benchmark(self, seq_len: int = 256, iterations: int = 20) -> Dict[str, float]:
        """ã‚¯ã‚¤ãƒƒã‚¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        print(f"\nğŸ ã‚¯ã‚¤ãƒƒã‚¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œä¸­... (seq_len={seq_len})")
        
        if not self.engine:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return {}
        
        results = self.engine.benchmark_inference(seq_len, iterations)
        self.performance_history.append({
            "timestamp": time.time(),
            "results": results,
            "config": self.engine.config.copy()
        })
        
        print(f"âš¡ é€Ÿåº¦: {results['tokens_per_second']:.1f} tok/s")
        print(f"â±ï¸  ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {results['avg_latency_ms']:.2f} ms")
        print(f"ğŸ–¥ï¸  ãƒ‡ãƒã‚¤ã‚¹: {results['device']}")
        
        return results
    
    def adjust_parameters(self):
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãƒ¡ãƒ‹ãƒ¥ãƒ¼"""
        if not self.engine:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        print("\nğŸ”§ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
        print("1. Î¸æ¸›è¡°ç‡ (gamma) èª¿æ•´")
        print("2. Î¸æœ‰åŠ¹/ç„¡åŠ¹åˆ‡ã‚Šæ›¿ãˆ")
        print("3. ãƒ¬ã‚¤ãƒ¤ãƒ¼æ¸›è¡°æœ‰åŠ¹/ç„¡åŠ¹")
        print("4. ç¾åœ¨ã®è¨­å®šè¡¨ç¤º")
        print("5. æˆ»ã‚‹")
        
        choice = input("\né¸æŠ (1-5): ").strip()
        
        if choice == "1":
            current_gamma = self.engine.config["theta_gamma"]
            print(f"ç¾åœ¨ã®Î³: {current_gamma}")
            new_gamma = input("æ–°ã—ã„Î³å€¤ (0.90-0.99): ").strip()
            try:
                gamma_val = float(new_gamma)
                if 0.90 <= gamma_val <= 0.99:
                    self.engine.config["theta_gamma"] = gamma_val
                    print(f"âœ… Î³ã‚’{gamma_val}ã«è¨­å®š")
                else:
                    print("âŒ ç¯„å›²å¤–ã§ã™ (0.90-0.99)")
            except ValueError:
                print("âŒ ç„¡åŠ¹ãªå€¤ã§ã™")
        
        elif choice == "2":
            current = self.engine.config["theta_enabled"]
            self.engine.config["theta_enabled"] = not current
            status = "æœ‰åŠ¹" if self.engine.config["theta_enabled"] else "ç„¡åŠ¹"
            print(f"âœ… Î¸ãƒ†ãƒ³ã‚½ãƒ«ã‚’{status}ã«è¨­å®š")
        
        elif choice == "3":
            current = self.engine.config["layer_decay"]
            self.engine.config["layer_decay"] = not current
            status = "æœ‰åŠ¹" if self.engine.config["layer_decay"] else "ç„¡åŠ¹"
            print(f"âœ… ãƒ¬ã‚¤ãƒ¤ãƒ¼æ¸›è¡°ã‚’{status}ã«è¨­å®š")
        
        elif choice == "4":
            print("\nğŸ“‹ ç¾åœ¨ã®è¨­å®š:")
            for key, value in self.engine.config.items():
                print(f"   {key}: {value}")
    
    def interactive_chat(self):
        """å¯¾è©±å‹ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
        if not self.engine:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        print("\nğŸ’¬ å¯¾è©±å‹ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆ")
        print("ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸ã¶ã‹ã€ç‹¬è‡ªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        print("'quit'ã§çµ‚äº†ã€'bench'ã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ")
        
        while True:
            print("\n" + "-"*40)
            print("ğŸ“ ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
            for i, prompt in enumerate(self.test_prompts, 1):
                print(f"{i}. {prompt}")
            print(f"{len(self.test_prompts)+1}. ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
            
            choice = input("\né¸æŠã¾ãŸã¯ã‚³ãƒãƒ³ãƒ‰: ").strip().lower()
            
            if choice == "quit":
                break
            elif choice == "bench":
                self.quick_benchmark()
                continue
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠ
            prompt = None
            try:
                choice_num = int(choice)
                if 1 <= choice_num <= len(self.test_prompts):
                    prompt = self.test_prompts[choice_num - 1]
                elif choice_num == len(self.test_prompts) + 1:
                    prompt = input("ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: ").strip()
            except ValueError:
                prompt = choice  # ç›´æ¥å…¥åŠ›ã¨ã—ã¦æ‰±ã†
            
            if prompt:
                self.run_inference_test(prompt)
    
    def run_inference_test(self, prompt: str):
        """æ¨è«–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print(f"\nğŸ§  æ¨è«–ãƒ†ã‚¹ãƒˆ: '{prompt[:50]}...'")
        
        # ãƒ€ãƒŸãƒ¼æ¨è«–ï¼ˆå®Ÿéš›ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã¯ç°¡ç•¥åŒ–ï¼‰
        start_time = time.time()
        
        # ç–‘ä¼¼çš„ãªæ¨è«–å‡¦ç†
        seq_len = len(prompt.split()) + 100  # å…¥åŠ›+ç”Ÿæˆäºˆå®štokens
        test_results = self.quick_benchmark(seq_len, 5)
        
        end_time = time.time()
        
        print(f"â±ï¸  æ¨è«–æ™‚é–“: {(end_time - start_time)*1000:.1f} ms")
        print(f"ğŸ“Š æ¨å®šç”Ÿæˆé€Ÿåº¦: {test_results.get('tokens_per_second', 0):.1f} tok/s")
        
        # ç–‘ä¼¼ç”Ÿæˆçµæœè¡¨ç¤º
        dummy_response = f"[NKAT-Generated Response for: {prompt[:30]}...] This is a simulated response demonstrating NKAT inference capabilities."
        print(f"ğŸ¤– ç”Ÿæˆçµæœ: {dummy_response}")
    
    def performance_analysis(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æè¡¨ç¤º"""
        if not self.performance_history:
            print("âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print("\nğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ")
        print("-"*50)
        
        speeds = [h["results"]["tokens_per_second"] for h in self.performance_history]
        latencies = [h["results"]["avg_latency_ms"] for h in self.performance_history]
        
        print(f"ğŸ“Š çµ±è¨ˆ:")
        print(f"   å¹³å‡é€Ÿåº¦: {np.mean(speeds):.1f} tok/s")
        print(f"   æœ€é«˜é€Ÿåº¦: {np.max(speeds):.1f} tok/s")
        print(f"   æœ€ä½é€Ÿåº¦: {np.min(speeds):.1f} tok/s")
        print(f"   å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {np.mean(latencies):.2f} ms")
        
        # è¨­å®šåˆ¥åˆ†æ
        theta_enabled_speeds = [h["results"]["tokens_per_second"] 
                               for h in self.performance_history 
                               if h["config"]["theta_enabled"]]
        theta_disabled_speeds = [h["results"]["tokens_per_second"] 
                                for h in self.performance_history 
                                if not h["config"]["theta_enabled"]]
        
        if theta_enabled_speeds and theta_disabled_speeds:
            speedup = np.mean(theta_enabled_speeds) / np.mean(theta_disabled_speeds)
            print(f"ğŸ”¥ NKATåŠ¹æœ: {(speedup-1)*100:+.1f}% é€Ÿåº¦å¤‰åŒ–")
    
    def export_results(self):
        """çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if not self.performance_history:
            print("âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        timestamp = int(time.time())
        filename = f"nkat_demo_results_{timestamp}.json"
        
        export_data = {
            "model": self.current_model,
            "timestamp": timestamp,
            "performance_history": self.performance_history,
            "summary": {
                "total_tests": len(self.performance_history),
                "avg_speed": np.mean([h["results"]["tokens_per_second"] for h in self.performance_history]),
                "device": self.performance_history[0]["results"]["device"] if self.performance_history else "unknown"
            }
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… çµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {filename}")
    
    def main_menu(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼"""
        while True:
            print("\n" + "="*40)
            print("ğŸ¯ NKAT Demo ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
            print("="*40)
            print("1. ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿")
            print("2. ã‚¯ã‚¤ãƒƒã‚¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
            print("3. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´")
            print("4. å¯¾è©±å‹ãƒãƒ£ãƒƒãƒˆãƒ†ã‚¹ãƒˆ")
            print("5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ")
            print("6. çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
            print("7. çµ‚äº†")
            
            choice = input("\né¸æŠ (1-7): ").strip()
            
            if choice == "1":
                model_path = input("ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: ").strip()
                if model_path and os.path.exists(model_path):
                    self.load_model(model_path)
                else:
                    print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            elif choice == "2":
                self.quick_benchmark()
            
            elif choice == "3":
                self.adjust_parameters()
            
            elif choice == "4":
                self.interactive_chat()
            
            elif choice == "5":
                self.performance_analysis()
            
            elif choice == "6":
                self.export_results()
            
            elif choice == "7":
                print("ğŸ‘‹ ãƒ‡ãƒ¢çµ‚äº†")
                break
            
            else:
                print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    demo = NKATInteractiveDemo()
    demo.show_banner()
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãŒã‚ã‚Œã°è‡ªå‹•èª­ã¿è¾¼ã¿
    if len(sys.argv) > 1:
        model_path = sys.argv[1]
        if os.path.exists(model_path):
            demo.load_model(model_path)
        else:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
    
    demo.main_menu()

if __name__ == "__main__":
    main() 