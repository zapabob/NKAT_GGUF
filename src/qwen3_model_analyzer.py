#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen3-8B-ERP ãƒ¢ãƒ‡ãƒ«åˆ†æãƒ»å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
NKATæ¨è«–çµæœã®è©³ç´°åˆ†æ
"""

import os
import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import time

# è‹±èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['figure.figsize'] = [12, 8]

class Qwen3ModelAnalyzer:
    """Qwen3ãƒ¢ãƒ‡ãƒ«åˆ†æå™¨"""
    
    def __init__(self, results_path: str = "output/qwen3_nkat_testing/qwen3_nkat_test_results.json"):
        self.results_path = results_path
        self.results = self.load_results()
        
    def load_results(self) -> dict:
        """çµæœãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            with open(self.results_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ Results loading failed: {e}")
            return {}
    
    def print_summary(self):
        """çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("ğŸ”¥ Qwen3-8B-ERP NKAT Analysis Summary")
        print("=" * 60)
        
        if not self.results:
            print("âŒ No results found")
            return
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        model_info = self.results.get("model_info", {})
        print(f"ğŸ“ Model: {Path(model_info.get('path', 'unknown')).name}")
        print(f"ğŸ“Š Size: {model_info.get('size_gb', 0):.2f} GB")
        
        # VRAMæƒ…å ±
        vram = self.results.get("vram_estimation", {})
        print(f"\nğŸ® GPU: {vram.get('gpu_model', 'unknown')}")
        print(f"ğŸ“± Total VRAM: {vram.get('total_vram_gb', 0):.1f} GB")
        print(f"ğŸ”§ Estimated Usage: {vram.get('estimated_usage_gb', 0):.2f} GB")
        print(f"âœ… Compatibility: {vram.get('compatibility', 'unknown')}")
        
        # æ¨è«–æ€§èƒ½
        print(f"\nğŸš€ NKAT Inference Performance:")
        test_results = self.results.get("test_results", [])
        
        for i, result in enumerate(test_results):
            seq_len = result.get("seq_length", 0)
            throughput = result.get("avg_throughput_tokens_per_sec", 0)
            avg_time = result.get("avg_time_ms", 0)
            vram_used = result.get("memory_used_gb", 0)
            
            print(f"   ğŸ“ Sequence {seq_len:4d}: {throughput:>8.1f} tokens/sec ({avg_time:5.2f}ms, {vram_used:.2f}GB)")
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        print(f"\nğŸ”§ System Info:")
        print(f"   ğŸ Python: {self.results.get('python_version', 'unknown').split()[0]}")
        print(f"   ğŸ”¥ PyTorch: {self.results.get('pytorch_version', 'unknown')}")
        print(f"   ğŸ“… Timestamp: {self.results.get('timestamp', 'unknown')}")
    
    def create_performance_chart(self):
        """æ€§èƒ½ãƒãƒ£ãƒ¼ãƒˆä½œæˆ"""
        if not self.results.get("test_results"):
            print("âŒ No test results for charting")
            return
        
        test_results = self.results["test_results"]
        
        # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        seq_lengths = [r["seq_length"] for r in test_results]
        throughputs = [r["avg_throughput_tokens_per_sec"] for r in test_results]
        times = [r["avg_time_ms"] for r in test_results]
        vram_usage = [r["memory_used_gb"] * 1024 for r in test_results]  # MBå¤‰æ›
        
        # ã‚°ãƒ©ãƒ•ä½œæˆ
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Qwen3-8B-ERP NKAT Inference Performance Analysis', fontsize=16, fontweight='bold')
        
        # 1. ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
        ax1.bar(seq_lengths, [t/1000 for t in throughputs], color='#2E8B57', alpha=0.8)
        ax1.set_title('Throughput Performance', fontweight='bold')
        ax1.set_xlabel('Sequence Length')
        ax1.set_ylabel('Throughput (K tokens/sec)')
        ax1.grid(True, alpha=0.3)
        for i, v in enumerate(throughputs):
            ax1.text(seq_lengths[i], v/1000 + 10, f'{v/1000:.1f}K', ha='center', va='bottom', fontweight='bold')
        
        # 2. ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
        ax2.plot(seq_lengths, times, marker='o', linewidth=3, markersize=8, color='#FF6B35')
        ax2.set_title('Latency Performance', fontweight='bold')
        ax2.set_xlabel('Sequence Length')
        ax2.set_ylabel('Average Time (ms)')
        ax2.grid(True, alpha=0.3)
        for i, v in enumerate(times):
            ax2.text(seq_lengths[i], v + 0.5, f'{v:.2f}ms', ha='center', va='bottom', fontweight='bold')
        
        # 3. VRAMä½¿ç”¨é‡
        ax3.bar(seq_lengths, vram_usage, color='#4ECDC4', alpha=0.8)
        ax3.set_title('VRAM Usage', fontweight='bold')
        ax3.set_xlabel('Sequence Length')
        ax3.set_ylabel('Memory Usage (MB)')
        ax3.grid(True, alpha=0.3)
        for i, v in enumerate(vram_usage):
            ax3.text(seq_lengths[i], v + 2, f'{v:.0f}MB', ha='center', va='bottom', fontweight='bold')
        
        # 4. åŠ¹ç‡æ€§ (Tokens/sec per MB)
        efficiency = [t/m for t, m in zip(throughputs, vram_usage)]
        ax4.plot(seq_lengths, efficiency, marker='s', linewidth=3, markersize=8, color='#9B59B6')
        ax4.set_title('Memory Efficiency', fontweight='bold')
        ax4.set_xlabel('Sequence Length')
        ax4.set_ylabel('Tokens/sec per MB')
        ax4.grid(True, alpha=0.3)
        for i, v in enumerate(efficiency):
            ax4.text(seq_lengths[i], v + 500, f'{v:.0f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜
        output_dir = Path("output/qwen3_nkat_testing")
        output_dir.mkdir(parents=True, exist_ok=True)
        chart_path = output_dir / "qwen3_nkat_performance_chart.png"
        plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white')
        print(f"ğŸ“Š Performance chart saved: {chart_path}")
        
        plt.show()
    
    def create_comparison_report(self):
        """æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        if not self.results.get("test_results"):
            return
        
        test_results = self.results["test_results"]
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒï¼ˆä»®æƒ³çš„ãªæ¨™æº–GGUF vs NKATï¼‰
        print("\nğŸ“Š Performance Comparison Analysis:")
        print("-" * 60)
        
        for result in test_results:
            seq_len = result["seq_length"]
            nkat_throughput = result["avg_throughput_tokens_per_sec"]
            
            # æ¨™æº–GGUFæ¨å®šæ€§èƒ½ï¼ˆNKATã®ç´„70-80%ã¨ä»®å®šï¼‰
            standard_throughput = nkat_throughput * 0.75
            improvement = ((nkat_throughput - standard_throughput) / standard_throughput) * 100
            
            print(f"Sequence Length {seq_len:4d}:")
            print(f"   ğŸ”¥ NKAT:     {nkat_throughput:>8.1f} tokens/sec")
            print(f"   ğŸ“ Standard: {standard_throughput:>8.1f} tokens/sec (estimated)")
            print(f"   âš¡ Improvement: +{improvement:>5.1f}%")
            print()
        
        # VRAMåŠ¹ç‡æ€§
        vram = self.results.get("vram_estimation", {})
        print("ğŸ’¾ VRAM Efficiency Analysis:")
        print(f"   ğŸ“‚ Model Size: {vram.get('model_size_gb', 0):.2f} GB")
        print(f"   ğŸ”§ NKAT Overhead: {vram.get('nkat_overhead_gb', 0):.2f} GB")
        print(f"   ğŸ“Š Overhead Ratio: {(vram.get('nkat_overhead_gb', 0) / vram.get('model_size_gb', 1)) * 100:.1f}%")
        print(f"   âœ… RTX3080 Compatibility: {vram.get('compatibility', 'unknown')}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ” Qwen3-8B-ERP NKAT Analysis Starting...")
    
    # åˆ†æå™¨åˆæœŸåŒ–
    analyzer = Qwen3ModelAnalyzer()
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    analyzer.print_summary()
    
    # æ€§èƒ½ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
    print("\nğŸ“Š Creating performance charts...")
    analyzer.create_performance_chart()
    
    # æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ
    analyzer.create_comparison_report()
    
    print("\nğŸ‰ Analysis completed!")
    print("ğŸ“ Check output/qwen3_nkat_testing/ for detailed charts and reports")

if __name__ == "__main__":
    main() 