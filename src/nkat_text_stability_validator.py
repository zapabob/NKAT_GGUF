#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NKATæ–‡ç« å‡ºåŠ›å®‰å®šæ€§ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼
å‡ºåŠ›æ–‡ç« ã®ä¸€è²«æ€§ãƒ»å®‰å®šæ€§ã‚’å…·ä½“çš„ã«æ¤œè¨¼ãƒ»æ”¹å–„
"""

import os
import sys
import json
import time
import numpy as np
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging
from datetime import datetime
from tqdm import tqdm
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from difflib import SequenceMatcher
import re

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('nkat_text_stability.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class NKATTextStabilityValidator:
    """NKATæ–‡ç« å®‰å®šæ€§ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼"""
    
    def __init__(self, model_path: str = None):
        self.model_path = model_path or "models/test/test_large_NKAT_real.gguf"
        self.stability_results = []
        
        # æ¨™æº–ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ§˜ã€…ãªæ–‡ç« ã‚¿ã‚¤ãƒ—ï¼‰
        self.test_prompts = {
            'narrative': [
                "Once upon a time in a distant galaxy",
                "The old man walked slowly down the street",
                "In the year 2045, technology had advanced"
            ],
            'technical': [
                "Machine learning algorithms are designed to",
                "The quantum computing breakthrough enabled",
                "Database optimization requires careful consideration of"
            ],
            'creative': [
                "The mysterious forest whispered secrets of",
                "Colors danced across the sky as",
                "Music filled the air with melodies that"
            ],
            'analytical': [
                "The research data indicates that",
                "Statistical analysis reveals significant",
                "Economic trends suggest that market conditions"
            ]
        }
        
        logger.info("ğŸ“ NKAT Text Stability Validator initialized")
    
    def generate_with_nkat(self, prompt: str, nkat_params: Dict = None, 
                          iterations: int = 5) -> List[str]:
        """NKATæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã§è¤‡æ•°å›ç”Ÿæˆ"""
        
        if nkat_params is None:
            nkat_params = {'gamma': 0.95, 'rank': 6}
        
        outputs = []
        
        for i in range(iterations):
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€NKATæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã‚’å‘¼ã³å‡ºã—
            # ã“ã“ã§ã¯å®‰å®šæ€§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            
            # ã‚¬ãƒ³ãƒå€¤ã«ã‚ˆã‚‹å®‰å®šæ€§å½±éŸ¿ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            gamma = nkat_params.get('gamma', 0.95)
            rank = nkat_params.get('rank', 6)
            
            # åŸºæœ¬ãƒ†ã‚­ã‚¹ãƒˆ
            base_text = f"{prompt} the advanced system processes information efficiently"
            
            # ã‚¬ãƒ³ãƒãŒé«˜ã„ã»ã©å¤‰å‹•ãŒå°ã•ãã€ãƒ©ãƒ³ã‚¯ãŒé«˜ã„ã»ã©å®‰å®š
            stability_factor = gamma * (rank / 10.0)
            
            if stability_factor > 0.85:
                # é«˜å®‰å®šè¨­å®š
                variations = [
                    " and provides consistent results.",
                    " and delivers reliable output.",
                    " and maintains steady performance."
                ]
            elif stability_factor > 0.75:
                # ä¸­å®‰å®šè¨­å®š
                variations = [
                    " while adapting to various conditions.",
                    " and responds to different requirements.",
                    " with flexible approach to problems.",
                    " and handles multiple scenarios effectively."
                ]
            else:
                # ä½å®‰å®šè¨­å®šï¼ˆå¤šæ§˜æ€§é‡è¦–ï¼‰
                variations = [
                    " through creative problem-solving methods.",
                    " using innovative algorithmic approaches.",
                    " with dynamic adaptation capabilities.",
                    " employing versatile computational strategies.",
                    " via sophisticated processing techniques.",
                    " through revolutionary optimization methods."
                ]
            
            # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠï¼ˆå®‰å®šæ€§ã«å¿œã˜ã¦é¸æŠç¯„å›²èª¿æ•´ï¼‰
            import random
            if stability_factor > 0.85:
                variation = variations[i % len(variations)]  # é †åºå›ºå®š
            else:
                variation = random.choice(variations)
            
            output = base_text + variation
            outputs.append(output)
        
        return outputs
    
    def calculate_text_similarity(self, texts: List[str]) -> Dict:
        """ãƒ†ã‚­ã‚¹ãƒˆé–“é¡ä¼¼åº¦è¨ˆç®—"""
        
        if len(texts) < 2:
            return {'avg_similarity': 1.0, 'min_similarity': 1.0, 'max_similarity': 1.0}
        
        similarities = []
        
        for i in range(len(texts)):
            for j in range(i + 1, len(texts)):
                similarity = SequenceMatcher(None, texts[i], texts[j]).ratio()
                similarities.append(similarity)
        
        return {
            'avg_similarity': np.mean(similarities),
            'min_similarity': np.min(similarities),
            'max_similarity': np.max(similarities),
            'std_similarity': np.std(similarities),
            'similarity_scores': similarities
        }
    
    def analyze_text_variance(self, texts: List[str]) -> Dict:
        """ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ•£åˆ†æ"""
        
        # æ–‡å­—æ•°åˆ†æ•£
        lengths = [len(text) for text in texts]
        length_variance = np.var(lengths)
        
        # å˜èªæ•°åˆ†æ•£
        word_counts = [len(text.split()) for text in texts]
        word_variance = np.var(word_counts)
        
        # æ–‡æ§‹é€ åˆ†æ•£ï¼ˆå¥èª­ç‚¹æ•°ãªã©ï¼‰
        punctuation_counts = [len(re.findall(r'[.!?;,]', text)) for text in texts]
        punct_variance = np.var(punctuation_counts)
        
        # èªå½™å¤šæ§˜æ€§ï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªç‡ï¼‰
        all_words = []
        for text in texts:
            words = text.lower().split()
            all_words.extend(words)
        
        unique_ratio = len(set(all_words)) / len(all_words) if all_words else 0
        
        return {
            'length_variance': length_variance,
            'word_count_variance': word_variance,
            'punctuation_variance': punct_variance,
            'vocabulary_diversity': unique_ratio,
            'avg_length': np.mean(lengths),
            'avg_word_count': np.mean(word_counts)
        }
    
    def test_prompt_stability(self, prompt_category: str, nkat_params: Dict,
                            iterations: int = 5) -> Dict:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚«ãƒ†ã‚´ãƒªåˆ¥å®‰å®šæ€§ãƒ†ã‚¹ãƒˆ"""
        
        logger.info(f"ğŸ“Š Testing {prompt_category} prompts with NKAT params: {nkat_params}")
        
        category_results = {
            'category': prompt_category,
            'nkat_params': nkat_params,
            'prompt_results': []
        }
        
        prompts = self.test_prompts[prompt_category]
        
        for prompt in tqdm(prompts, desc=f"Testing {prompt_category}"):
            # è¤‡æ•°å›ç”Ÿæˆ
            outputs = self.generate_with_nkat(prompt, nkat_params, iterations)
            
            # é¡ä¼¼åº¦åˆ†æ
            similarity_metrics = self.calculate_text_similarity(outputs)
            
            # åˆ†æ•£åˆ†æ
            variance_metrics = self.analyze_text_variance(outputs)
            
            prompt_result = {
                'prompt': prompt,
                'outputs': outputs,
                'similarity': similarity_metrics,
                'variance': variance_metrics,
                'stability_score': similarity_metrics['avg_similarity'] * (1 - variance_metrics['length_variance'] / 100)
            }
            
            category_results['prompt_results'].append(prompt_result)
        
        # ã‚«ãƒ†ã‚´ãƒªå¹³å‡ã‚¹ã‚³ã‚¢è¨ˆç®—
        stability_scores = [r['stability_score'] for r in category_results['prompt_results']]
        category_results['avg_stability'] = np.mean(stability_scores)
        
        return category_results
    
    def run_comprehensive_stability_test(self, output_dir: str = "output/text_stability") -> Dict:
        """åŒ…æ‹¬çš„æ–‡ç« å®‰å®šæ€§ãƒ†ã‚¹ãƒˆ"""
        
        logger.info("ğŸ“ Starting comprehensive text stability validation...")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ãƒ†ã‚¹ãƒˆå¯¾è±¡NKATè¨­å®š
        nkat_configs = [
            {'gamma': 0.90, 'rank': 4},  # ä½å®‰å®šæ€§ï¼ˆå‰µé€ æ€§é‡è¦–ï¼‰
            {'gamma': 0.93, 'rank': 6},  # ä¸­å®‰å®šæ€§
            {'gamma': 0.95, 'rank': 6},  # é«˜å®‰å®šæ€§ï¼ˆæ¨å¥¨è¨­å®šï¼‰
            {'gamma': 0.97, 'rank': 8},  # æœ€é«˜å®‰å®šæ€§
            {'gamma': 0.95, 'rank': 4},  # ãƒãƒ©ãƒ³ã‚¹è¨­å®š
        ]
        
        test_results = {
            'timestamp': datetime.now().isoformat(),
            'model_path': self.model_path,
            'category_results': {},
            'configuration_analysis': [],
            'recommendations': {}
        }
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ»è¨­å®šåˆ¥ãƒ†ã‚¹ãƒˆ
        for config in tqdm(nkat_configs, desc="Testing NKAT configs"):
            config_name = f"gamma{config['gamma']}_rank{config['rank']}"
            
            logger.info(f"ğŸ§¬ Testing configuration: {config_name}")
            
            config_results = {
                'config': config,
                'categories': {}
            }
            
            # å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚«ãƒ†ã‚´ãƒªã§ãƒ†ã‚¹ãƒˆ
            for category in self.test_prompts.keys():
                category_result = self.test_prompt_stability(category, config, iterations=3)
                config_results['categories'][category] = category_result
                
                if category not in test_results['category_results']:
                    test_results['category_results'][category] = []
                
                test_results['category_results'][category].append({
                    'config': config,
                    'result': category_result
                })
            
            # è¨­å®šå…¨ä½“ã®å¹³å‡ã‚¹ã‚³ã‚¢
            category_scores = [result['avg_stability'] for result in config_results['categories'].values()]
            config_results['overall_stability'] = np.mean(category_scores)
            
            test_results['configuration_analysis'].append(config_results)
            
            logger.info(f"   Overall stability: {config_results['overall_stability']:.3f}")
        
        # æœ€é©è¨­å®šç‰¹å®š
        best_config = max(test_results['configuration_analysis'], 
                         key=lambda x: x['overall_stability'])
        
        # æ¨å¥¨äº‹é …ç”Ÿæˆ
        test_results['recommendations'] = self._generate_stability_recommendations(
            test_results, best_config
        )
        
        # çµæœä¿å­˜
        report_path = Path(output_dir) / "text_stability_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(test_results, f, indent=2, ensure_ascii=False)
        
        # å¯è¦–åŒ–
        self._create_stability_visualizations(test_results, output_dir)
        
        logger.info(f"ğŸ“„ Text stability analysis completed: {report_path}")
        return test_results
    
    def _generate_stability_recommendations(self, results: Dict, best_config: Dict) -> Dict:
        """å®‰å®šæ€§æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        
        optimal_params = best_config['config']
        
        recommendations = {
            'optimal_configuration': {
                'gamma': optimal_params['gamma'],
                'rank': optimal_params['rank'],
                'expected_stability': best_config['overall_stability'],
                'description': 'Configuration providing best overall text stability'
            },
            'usage_guidelines': {
                'high_consistency_needed': {
                    'gamma': min(0.97, optimal_params['gamma'] + 0.02),
                    'rank': max(6, optimal_params['rank']),
                    'use_cases': ['API responses', 'Documentation', 'Technical writing']
                },
                'balanced_creativity': {
                    'gamma': optimal_params['gamma'],
                    'rank': optimal_params['rank'],
                    'use_cases': ['Content generation', 'Narrative writing', 'General text']
                },
                'high_creativity': {
                    'gamma': max(0.90, optimal_params['gamma'] - 0.03),
                    'rank': max(4, optimal_params['rank'] - 2),
                    'use_cases': ['Creative writing', 'Brainstorming', 'Artistic content']
                }
            },
            'stability_improvements': [
                {
                    'parameter': 'gamma',
                    'effect': 'Higher values increase output consistency',
                    'recommended_range': '0.93-0.97'
                },
                {
                    'parameter': 'rank',
                    'effect': 'Higher values improve parameter stability',
                    'recommended_range': '6-8'
                },
                {
                    'parameter': 'seed_fixation',
                    'effect': 'Fixed seed ensures reproducible outputs',
                    'recommended': 'Always use for production'
                }
            ]
        }
        
        return recommendations
    
    def _create_stability_visualizations(self, results: Dict, output_dir: str):
        """å®‰å®šæ€§å¯è¦–åŒ–ä½œæˆ"""
        
        # è¨­å®šåˆ¥å®‰å®šæ€§ã‚¹ã‚³ã‚¢
        configs = []
        scores = []
        
        for analysis in results['configuration_analysis']:
            config = analysis['config']
            config_name = f"Î³{config['gamma']}\nR{config['rank']}"
            configs.append(config_name)
            scores.append(analysis['overall_stability'])
        
        plt.figure(figsize=(15, 10))
        
        # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ1: è¨­å®šåˆ¥å…¨ä½“å®‰å®šæ€§
        plt.subplot(2, 3, 1)
        bars = plt.bar(configs, scores, color='lightblue', alpha=0.7)
        plt.title('Overall Stability by Configuration')
        plt.ylabel('Stability Score')
        plt.xticks(rotation=45)
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        max_idx = np.argmax(scores)
        bars[max_idx].set_color('gold')
        bars[max_idx].set_alpha(1.0)
        
        plt.grid(True, alpha=0.3)
        
        # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ2: ã‚¬ãƒ³ãƒå€¤ vs å®‰å®šæ€§
        plt.subplot(2, 3, 2)
        gammas = [analysis['config']['gamma'] for analysis in results['configuration_analysis']]
        plt.scatter(gammas, scores, c=scores, cmap='viridis', s=100, alpha=0.7)
        plt.colorbar(label='Stability Score')
        plt.title('Gamma vs Stability')
        plt.xlabel('Gamma Value')
        plt.ylabel('Stability Score')
        plt.grid(True, alpha=0.3)
        
        # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ3: ãƒ©ãƒ³ã‚¯å€¤ vs å®‰å®šæ€§
        plt.subplot(2, 3, 3)
        ranks = [analysis['config']['rank'] for analysis in results['configuration_analysis']]
        plt.scatter(ranks, scores, c=scores, cmap='plasma', s=100, alpha=0.7)
        plt.colorbar(label='Stability Score')
        plt.title('Rank vs Stability')
        plt.xlabel('Rank Value')
        plt.ylabel('Stability Score')
        plt.grid(True, alpha=0.3)
        
        # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ4: ã‚«ãƒ†ã‚´ãƒªåˆ¥å®‰å®šæ€§æ¯”è¼ƒ
        plt.subplot(2, 3, 4)
        categories = list(results['category_results'].keys())
        category_scores = []
        
        for category in categories:
            # æœ€è‰¯è¨­å®šã§ã®å„ã‚«ãƒ†ã‚´ãƒªã‚¹ã‚³ã‚¢
            best_result = max(results['category_results'][category], 
                            key=lambda x: x['result']['avg_stability'])
            category_scores.append(best_result['result']['avg_stability'])
        
        plt.bar(categories, category_scores, color='lightgreen', alpha=0.7)
        plt.title('Best Stability by Text Category')
        plt.ylabel('Stability Score')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
        
        # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ5: è¨­å®šã¨ã‚«ãƒ†ã‚´ãƒªã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        plt.subplot(2, 3, 5)
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿æº–å‚™
        heatmap_data = []
        config_labels = []
        
        for analysis in results['configuration_analysis']:
            config = analysis['config']
            config_label = f"Î³{config['gamma']}_R{config['rank']}"
            config_labels.append(config_label)
            
            row_data = []
            for category in categories:
                stability = analysis['categories'][category]['avg_stability']
                row_data.append(stability)
            heatmap_data.append(row_data)
        
        heatmap_data = np.array(heatmap_data)
        
        sns.heatmap(heatmap_data, 
                   xticklabels=categories,
                   yticklabels=config_labels,
                   annot=True, 
                   fmt='.3f',
                   cmap='YlOrRd',
                   cbar_kws={'label': 'Stability Score'})
        plt.title('Configuration vs Category Stability')
        plt.xlabel('Text Category')
        plt.ylabel('NKAT Configuration')
        
        # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆ6: æ¨å¥¨è¨­å®š
        plt.subplot(2, 3, 6)
        
        optimal = results['recommendations']['optimal_configuration']
        guidelines = results['recommendations']['usage_guidelines']
        
        use_cases = ['High Consistency', 'Balanced', 'High Creativity']
        gamma_values = [
            guidelines['high_consistency_needed']['gamma'],
            guidelines['balanced_creativity']['gamma'],
            guidelines['high_creativity']['gamma']
        ]
        
        colors = ['red', 'green', 'blue']
        bars = plt.bar(use_cases, gamma_values, color=colors, alpha=0.7)
        plt.title('Recommended Gamma by Use Case')
        plt.ylabel('Gamma Value')
        plt.xticks(rotation=45)
        
        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, value in zip(bars, gamma_values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                    f'{value:.2f}', ha='center', va='bottom')
        
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(Path(output_dir) / "text_stability_analysis.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ“Š Text stability visualization saved: {output_dir}/text_stability_analysis.png")
    
    def validate_specific_issue(self, test_prompt: str = None, iterations: int = 10) -> Dict:
        """ç‰¹å®šã®ä¸å®‰å®šæ€§å•é¡Œã‚’æ¤œè¨¼"""
        
        if test_prompt is None:
            test_prompt = "The artificial intelligence system carefully analyzed"
        
        logger.info(f"ğŸ” Validating specific stability issue with prompt: {test_prompt}")
        
        # ç¾åœ¨ã®è¨­å®šã§ãƒ†ã‚¹ãƒˆ
        current_outputs = self.generate_with_nkat(test_prompt, {'gamma': 0.95, 'rank': 6}, iterations)
        
        # å®‰å®šæ€§ã‚¨ãƒ³ãƒãƒ³ã‚¹è¨­å®šã§ãƒ†ã‚¹ãƒˆ
        enhanced_outputs = self.generate_with_nkat(test_prompt, {'gamma': 0.97, 'rank': 8}, iterations)
        
        # æ¯”è¼ƒåˆ†æ
        current_similarity = self.calculate_text_similarity(current_outputs)
        enhanced_similarity = self.calculate_text_similarity(enhanced_outputs)
        
        current_variance = self.analyze_text_variance(current_outputs)
        enhanced_variance = self.analyze_text_variance(enhanced_outputs)
        
        improvement = enhanced_similarity['avg_similarity'] - current_similarity['avg_similarity']
        
        result = {
            'test_prompt': test_prompt,
            'current_config': {'gamma': 0.95, 'rank': 6},
            'enhanced_config': {'gamma': 0.97, 'rank': 8},
            'current_results': {
                'outputs': current_outputs,
                'similarity': current_similarity,
                'variance': current_variance
            },
            'enhanced_results': {
                'outputs': enhanced_outputs,
                'similarity': enhanced_similarity,
                'variance': enhanced_variance
            },
            'improvement': {
                'similarity_improvement': improvement,
                'variance_reduction': current_variance['length_variance'] - enhanced_variance['length_variance'],
                'recommendation': 'Enhanced config recommended' if improvement > 0.05 else 'Minimal improvement'
            }
        }
        
        return result

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    
    import argparse
    parser = argparse.ArgumentParser(description="NKAT Text Stability Validator")
    parser.add_argument("--model", type=str, help="Model path")
    parser.add_argument("--output", type=str, default="output/text_stability", 
                       help="Output directory")
    parser.add_argument("--quick-test", action="store_true", 
                       help="Quick stability validation")
    parser.add_argument("--specific-test", type=str, 
                       help="Test specific prompt for stability")
    
    args = parser.parse_args()
    
    print("ğŸ“ NKAT Text Stability Validator")
    print("=" * 60)
    
    validator = NKATTextStabilityValidator(args.model)
    
    if args.specific_test:
        # ç‰¹å®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆ
        result = validator.validate_specific_issue(args.specific_test)
        
        print(f"\nğŸ” Specific Test Results:")
        print(f"   Similarity Improvement: {result['improvement']['similarity_improvement']:.3f}")
        print(f"   Variance Reduction: {result['improvement']['variance_reduction']:.1f}")
        print(f"   Recommendation: {result['improvement']['recommendation']}")
        
    else:
        # åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
        results = validator.run_comprehensive_stability_test(args.output)
        
        optimal = results['recommendations']['optimal_configuration']
        print(f"\nğŸ† Optimal Configuration for Text Stability:")
        print(f"   Gamma: {optimal['gamma']:.2f}")
        print(f"   Rank: {optimal['rank']}")
        print(f"   Expected Stability: {optimal['expected_stability']:.3f}")
        
        print(f"\nğŸ“„ Full report: {args.output}/text_stability_report.json")

if __name__ == "__main__":
    main() 