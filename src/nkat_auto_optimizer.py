#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NKAT Auto Optimizer
è‡ªå‹•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã¨TPEã‚¹ã‚³ã‚¢æœ€å¤§åŒ–
"""

import os
import sys
import json
import argparse
import numpy as np
import torch
from pathlib import Path
import logging
from tqdm import tqdm
import optuna
import subprocess
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # GUIç„¡åŠ¹åŒ–
plt.rcParams['font.size'] = 10
import warnings
warnings.filterwarnings('ignore')

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from nkat_gguf_converter import NKATGGUFConverter, calculate_tpe_score
from nkat_inference_engine import NKATInferenceEngine

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('nkat_optimization.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class NKATAutoOptimizer:
    """NKATè‡ªå‹•æœ€é©åŒ–å™¨"""
    
    def __init__(self, base_model_path: str, output_dir: str = "output/optimized"):
        self.base_model_path = base_model_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.optimization_history = []
        self.best_params = None
        self.best_score = -np.inf
        
        logger.info(f"ğŸš€ NKAT Auto Optimizer åˆæœŸåŒ–")
        logger.info(f"   ğŸ“ ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«: {base_model_path}")
        logger.info(f"   ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
    
    def objective(self, trial: optuna.Trial) -> float:
        """Optunaæœ€é©åŒ–é–¢æ•°"""
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ç¯„å›²
        theta_rank = trial.suggest_int('theta_rank', 2, 8, step=2)
        theta_gamma = trial.suggest_float('theta_gamma', 0.90, 0.99, step=0.01)
        
        logger.info(f"ğŸ§ª Trial {trial.number}: rank={theta_rank}, gamma={theta_gamma}")
        
        try:
            # NKAT-GGUFå¤‰æ›
            output_path = self.output_dir / f"trial_{trial.number}_rank{theta_rank}_gamma{theta_gamma:.2f}.nkat"
            converter = NKATGGUFConverter(theta_rank, theta_gamma)
            
            success = converter.convert_to_nkat_gguf(
                self.base_model_path, 
                str(output_path)
            )
            
            if not success:
                logger.warning(f"   âŒ å¤‰æ›å¤±æ•—: trial {trial.number}")
                return -1000.0
            
            # æ¨è«–æ€§èƒ½è©•ä¾¡
            engine = NKATInferenceEngine(str(output_path))
            if not engine.load_model():
                logger.warning(f"   âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: trial {trial.number}")
                return -1000.0
            
            # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
            benchmark_results = engine.benchmark_inference(
                sequence_length=256,  # çŸ­ç¸®ã—ã¦é«˜é€ŸåŒ–
                num_iterations=20
            )
            
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ
            comparison = engine.compare_with_baseline(256)
            
            # ç–‘ä¼¼perplexityè¨ˆç®—ï¼ˆå®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯æ¨è«–ã§è¨ˆç®—ï¼‰
            mock_perplexity = self._estimate_perplexity(theta_rank, theta_gamma)
            
            # TPEã‚¹ã‚³ã‚¢è¨ˆç®—
            lambda_theta = theta_rank * 0.05  # rankã«æ¯”ä¾‹ã™ã‚‹Î»
            tpe_score = calculate_tpe_score(mock_perplexity, lambda_theta)
            
            # çµæœè¨˜éŒ²
            result = {
                "trial": trial.number,
                "theta_rank": theta_rank,
                "theta_gamma": theta_gamma,
                "tokens_per_second": benchmark_results["tokens_per_second"],
                "overhead_percentage": comparison["overhead_percentage"],
                "estimated_perplexity": mock_perplexity,
                "tpe_score": tpe_score,
                "lambda_theta": lambda_theta
            }
            
            self.optimization_history.append(result)
            
            logger.info(f"   ğŸ“Š trial {trial.number}: TPE={tpe_score:.4f}")
            logger.info(f"      tok/s={benchmark_results['tokens_per_second']:.1f}")
            logger.info(f"      overhead={comparison['overhead_percentage']:+.1f}%")
            logger.info(f"      est_ppl={mock_perplexity:.3f}")
            
            # æœ€è‰¯çµæœæ›´æ–°
            if tpe_score > self.best_score:
                self.best_score = tpe_score
                self.best_params = result.copy()
                logger.info(f"   ğŸ† æ–°ãƒ™ã‚¹ãƒˆ! TPE={tpe_score:.4f}")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç¯€ç´„ï¼‰
            if output_path.exists():
                output_path.unlink()
            
            return tpe_score
            
        except Exception as e:
            logger.error(f"   âŒ trial {trial.number} å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return -1000.0
    
    def _estimate_perplexity(self, theta_rank: int, theta_gamma: float) -> float:
        """ç–‘ä¼¼perplexityæ¨å®šï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å®Ÿæ¨è«–ãŒå¿…è¦ï¼‰"""
        # ç°¡æ˜“ãƒ¢ãƒ‡ãƒ«ï¼šrankâ†‘ã§perplexityâ†“ã€gammaæœ€é©å€¤å‘¨è¾ºã§æœ€å°
        base_ppl = 6.5
        rank_effect = -0.03 * theta_rank  # ranké«˜ã„ã»ã©æ”¹å–„
        gamma_effect = -0.2 * np.exp(-((theta_gamma - 0.97) / 0.02) ** 2)  # 0.97ä»˜è¿‘ã§æœ€è‰¯
        noise = np.random.normal(0, 0.05)  # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º
        
        estimated_ppl = base_ppl + rank_effect + gamma_effect + noise
        return max(estimated_ppl, 3.0)  # æœ€å°å€¤åˆ¶é™
    
    def run_optimization(self, n_trials: int = 50) -> Dict:
        """æœ€é©åŒ–å®Ÿè¡Œ"""
        logger.info(f"ğŸ” NKATæœ€é©åŒ–é–‹å§‹: {n_trials} trials")
        
        # Optuna studyä½œæˆ
        study = optuna.create_study(
            direction='maximize',
            study_name='nkat_optimization',
            pruner=optuna.pruners.MedianPruner(n_warmup_steps=5)
        )
        
        # æœ€é©åŒ–å®Ÿè¡Œ
        study.optimize(self.objective, n_trials=n_trials)
        
        # çµæœè§£æ
        best_trial = study.best_trial
        logger.info(f"ğŸ† æœ€é©åŒ–å®Œäº†!")
        logger.info(f"   ğŸ¯ ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {best_trial.value:.4f}")
        logger.info(f"   âš™ï¸  ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
        for key, value in best_trial.params.items():
            logger.info(f"      {key}: {value}")
        
        # çµæœä¿å­˜
        self._save_optimization_results(study)
        
        # æœ€é©ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆ
        best_model_path = self._generate_optimal_model(best_trial.params)
        
        return {
            "best_params": best_trial.params,
            "best_score": best_trial.value,
            "best_model_path": best_model_path,
            "optimization_history": self.optimization_history,
            "study": study
        }
    
    def _save_optimization_results(self, study: optuna.Study):
        """æœ€é©åŒ–çµæœä¿å­˜"""
        # å±¥æ­´ã‚’JSONä¿å­˜
        history_file = self.output_dir / "optimization_history.json"
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(self.optimization_history, f, indent=2, ensure_ascii=False)
        
        # Optunaçµæœä¿å­˜
        study_file = self.output_dir / "optuna_study.json"
        with open(study_file, 'w', encoding='utf-8') as f:
            study_summary = {
                "best_trial": {
                    "number": study.best_trial.number,
                    "value": study.best_trial.value,
                    "params": study.best_trial.params
                },
                "n_trials": len(study.trials),
                "direction": study.direction.name
            }
            json.dump(study_summary, f, indent=2, ensure_ascii=False)
        
        # å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ç”Ÿæˆ
        self._plot_optimization_results(study)
        
        logger.info(f"ğŸ“„ çµæœä¿å­˜å®Œäº†:")
        logger.info(f"   ğŸ“Š å±¥æ­´: {history_file}")
        logger.info(f"   ğŸ”¬ Study: {study_file}")
    
    def _plot_optimization_results(self, study: optuna.Study):
        """æœ€é©åŒ–çµæœå¯è¦–åŒ–"""
        try:
            # 1. TPEã‚¹ã‚³ã‚¢æ¨ç§»
            plt.figure(figsize=(12, 8))
            
            plt.subplot(2, 2, 1)
            values = [trial.value for trial in study.trials if trial.value is not None]
            plt.plot(values, 'b-', alpha=0.7)
            plt.title('TPE Score Progress', fontsize=10)
            plt.xlabel('Trial', fontsize=8)
            plt.ylabel('TPE Score', fontsize=8)
            plt.grid(True, alpha=0.3)
            
            # 2. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒ
            plt.subplot(2, 2, 2)
            ranks = [h["theta_rank"] for h in self.optimization_history]
            gammas = [h["theta_gamma"] for h in self.optimization_history]
            scores = [h["tpe_score"] for h in self.optimization_history]
            
            scatter = plt.scatter(ranks, gammas, c=scores, cmap='viridis', alpha=0.7)
            plt.colorbar(scatter, label='TPE Score')
            plt.title('Parameter Space Exploration', fontsize=10)
            plt.xlabel('Theta Rank', fontsize=8)
            plt.ylabel('Theta Gamma', fontsize=8)
            
            # 3. Perplexity vs Speed
            plt.subplot(2, 2, 3)
            ppls = [h["estimated_perplexity"] for h in self.optimization_history]
            speeds = [h["tokens_per_second"] for h in self.optimization_history]
            
            plt.scatter(ppls, speeds, c=scores, cmap='plasma', alpha=0.7)
            plt.colorbar(label='TPE Score')
            plt.title('Perplexity vs Speed', fontsize=10)
            plt.xlabel('Estimated Perplexity', fontsize=8)
            plt.ylabel('Tokens/sec', fontsize=8)
            
            # 4. ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰åˆ†å¸ƒ
            plt.subplot(2, 2, 4)
            overheads = [h["overhead_percentage"] for h in self.optimization_history]
            plt.hist(overheads, bins=20, alpha=0.7, color='orange')
            plt.title('Speed Overhead Distribution', fontsize=10)
            plt.xlabel('Overhead (%)', fontsize=8)
            plt.ylabel('Frequency', fontsize=8)
            plt.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plot_file = self.output_dir / "optimization_results.png"
            plt.savefig(plot_file, dpi=150, bbox_inches='tight')
            plt.close()
            
            logger.info(f"   ğŸ“ˆ å¯è¦–åŒ–: {plot_file}")
            
        except Exception as e:
            logger.warning(f"âš ï¸  å¯è¦–åŒ–å¤±æ•—: {e}")
    
    def _generate_optimal_model(self, best_params: Dict) -> str:
        """æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆ"""
        logger.info(f"ğŸ­ æœ€é©ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆä¸­...")
        
        output_path = self.output_dir / f"optimal_rank{best_params['theta_rank']}_gamma{best_params['theta_gamma']:.2f}.nkat"
        
        converter = NKATGGUFConverter(
            best_params['theta_rank'], 
            best_params['theta_gamma']
        )
        
        success = converter.convert_to_nkat_gguf(
            self.base_model_path,
            str(output_path)
        )
        
        if success:
            logger.info(f"âœ… æœ€é©ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆå®Œäº†: {output_path}")
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            config_file = output_path.with_suffix('.json')
            config = {
                "optimal_parameters": best_params,
                "base_model": self.base_model_path,
                "optimization_timestamp": str(torch.tensor(0).item()),  # ãƒ€ãƒŸãƒ¼
                "usage_command": f"py -3 nkat_inference_engine.py -m {output_path} --theta-gamma {best_params['theta_gamma']} --benchmark"
            }
            
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            return str(output_path)
        else:
            logger.error(f"âŒ æœ€é©ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆå¤±æ•—")
            return ""

def run_quick_optimization(model_path: str, output_dir: str = "output/quick") -> Dict:
    """ã‚¯ã‚¤ãƒƒã‚¯æœ€é©åŒ–ï¼ˆå°‘æ•°trialï¼‰"""
    logger.info(f"âš¡ ã‚¯ã‚¤ãƒƒã‚¯æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰")
    
    optimizer = NKATAutoOptimizer(model_path, output_dir)
    results = optimizer.run_optimization(n_trials=12)  # å°‘æ•°trial
    
    return results

def run_full_optimization(model_path: str, output_dir: str = "output/full") -> Dict:
    """å®Œå…¨æœ€é©åŒ–ï¼ˆå¤šæ•°trialï¼‰"""
    logger.info(f"ğŸ”¬ å®Œå…¨æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰")
    
    optimizer = NKATAutoOptimizer(model_path, output_dir)
    results = optimizer.run_optimization(n_trials=100)  # å¤šæ•°trial
    
    return results

def main():
    parser = argparse.ArgumentParser(description="NKAT Auto Optimizer")
    parser.add_argument("--model", "-m", required=True, help="ãƒ™ãƒ¼ã‚¹GGUFãƒ¢ãƒ‡ãƒ«")
    parser.add_argument("--output-dir", "-o", default="output/optimized", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--mode", choices=["quick", "full", "custom"], default="quick", help="æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰")
    parser.add_argument("--trials", type=int, default=50, help="trialæ•°ï¼ˆcustomãƒ¢ãƒ¼ãƒ‰ç”¨ï¼‰")
    parser.add_argument("--target-rank", type=int, help="ç‰¹å®šrankæŒ‡å®š")
    parser.add_argument("--target-gamma", type=float, help="ç‰¹å®šgammaæŒ‡å®š")
    
    args = parser.parse_args()
    
    # ãƒ¢ãƒ‡ãƒ«å­˜åœ¨ç¢ºèª
    if not os.path.exists(args.model):
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.model}")
        sys.exit(1)
    
    # ç‰¹å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŒ‡å®šã®å ´åˆ
    if args.target_rank and args.target_gamma:
        logger.info(f"ğŸ¯ ç‰¹å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å®Ÿè¡Œ: rank={args.target_rank}, gamma={args.target_gamma}")
        
        converter = NKATGGUFConverter(args.target_rank, args.target_gamma)
        output_path = Path(args.output_dir) / f"target_rank{args.target_rank}_gamma{args.target_gamma:.2f}.nkat"
        
        success = converter.convert_to_nkat_gguf(args.model, str(output_path))
        if success:
            print(f"âœ… å®Œäº†: {output_path}")
        sys.exit(0)
    
    # æœ€é©åŒ–å®Ÿè¡Œ
    if args.mode == "quick":
        results = run_quick_optimization(args.model, args.output_dir)
    elif args.mode == "full":
        results = run_full_optimization(args.model, args.output_dir)
    else:  # custom
        optimizer = NKATAutoOptimizer(args.model, args.output_dir)
        results = optimizer.run_optimization(args.trials)
    
    # çµæœè¡¨ç¤º
    print(f"\nğŸ‰ NKATæœ€é©åŒ–å®Œäº†!")
    print(f"ğŸ† ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    for key, value in results["best_params"].items():
        print(f"   {key}: {value}")
    print(f"ğŸ“Š ãƒ™ã‚¹ãƒˆTPEã‚¹ã‚³ã‚¢: {results['best_score']:.4f}")
    print(f"ğŸ“ æœ€é©ãƒ¢ãƒ‡ãƒ«: {results['best_model_path']}")
    
    print(f"\nğŸš€ ä½¿ç”¨ä¾‹:")
    print(f"py -3 nkat_inference_engine.py -m {results['best_model_path']} --benchmark")

if __name__ == "__main__":
    main() 