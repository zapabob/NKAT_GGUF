# ğŸš€ NKAT-GGUF llama.cppçµ±åˆã‚¬ã‚¤ãƒ‰

**éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ãƒ»ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã«ã‚ˆã‚‹llama.cppæ‹¡å¼µ**

## ğŸ“‹ çµ±åˆæ¦‚è¦

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€æ—¢ã«é–‹ç™ºæ¸ˆã¿ã®NKAT CUDA ã‚«ãƒ¼ãƒãƒ«ã¨GGUFæ‹¡å¼µã‚’llama.cppã«çµ±åˆã™ã‚‹æ‰‹é †ã‚’èª¬æ˜ã—ã¾ã™ã€‚

### ğŸ¯ çµ±åˆå†…å®¹

1. **CUDA ã‚«ãƒ¼ãƒãƒ«çµ±åˆ** - Moyal star productæ¼”ç®—ã‚«ãƒ¼ãƒãƒ«
2. **GGUFæ‹¡å¼µå¯¾å¿œ** - Î¸ãƒ†ãƒ³ã‚½ãƒ«ä»˜ãGGUFãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒãƒ¼ãƒˆ
3. **æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆ** - éå¯æ›æ¼”ç®—ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š
4. **RTX3080æœ€é©åŒ–** - Ampereã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç‰¹åŒ–

## ğŸ› ï¸ çµ±åˆæ‰‹é †

### Step 1: llama.cppãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æº–å‚™

```powershell
# llama.cppã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/ggerganov/llama.cpp.git
cd llama.cpp

# æœ€æ–°ç‰ˆã«æ›´æ–°
git pull origin master
```

### Step 2: NKAT CUDAãƒ•ã‚¡ã‚¤ãƒ«ã®çµ±åˆ

```powershell
# CUDAã‚«ãƒ¼ãƒãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
copy "C:\Users\downl\Desktop\NKAT_GGUF\output\cuda_kernels\nkat_star_gemm_kernels.cu" "src\ggml-cuda\"
copy "C:\Users\downl\Desktop\NKAT_GGUF\output\cuda_kernels\nkat_cuda_interface.cpp" "src\ggml-cuda\"
copy "C:\Users\downl\Desktop\NKAT_GGUF\output\cuda_kernels\nkat_cuda.h" "src\ggml-cuda\"
```

### Step 3: CMakeLists.txtä¿®æ­£

llama.cpp/CMakeLists.txtã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

```cmake
# NKAT CUDA Integration
if(LLAMA_CUBLAS)
    # NKAT CUDA sources
    set(NKAT_CUDA_SOURCES
        src/ggml-cuda/nkat_star_gemm_kernels.cu
        src/ggml-cuda/nkat_cuda_interface.cpp
    )
    
    # NKAT headers
    set(NKAT_CUDA_HEADERS
        src/ggml-cuda/nkat_cuda.h
    )
    
    # RTX3080 (Ampere) optimization
    set_property(TARGET ggml-cuda PROPERTY CUDA_ARCHITECTURES 86)
    
    # Add NKAT sources
    target_sources(ggml-cuda PRIVATE ${NKAT_CUDA_SOURCES})
    target_include_directories(ggml-cuda PRIVATE src/ggml-cuda)
    
    # NKAT definitions
    target_compile_definitions(ggml-cuda PRIVATE 
        GGML_CUDA_NKAT_ENABLED
        NKAT_CUDA_ARCH=86
    )
    
    # Performance flags
    target_compile_options(ggml-cuda PRIVATE 
        $<$<COMPILE_LANGUAGE:CUDA>:
            --use_fast_math
            --optimize=3
            --maxrregcount=128
        >
    )
endif()
```

### Step 4: ggml-cuda.cuä¿®æ­£

src/ggml-cuda.cuã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

```cpp
#ifdef GGML_CUDA_NKAT_ENABLED
#include "nkat_cuda.h"

// NKATæ¼”ç®—å­ã®è¿½åŠ 
void ggml_cuda_op_nkat_star_mul(ggml_backend_cuda_context * ctx, ggml_tensor * dst) {
    const ggml_tensor * src0 = dst->src[0]; // Weight matrix
    const ggml_tensor * src1 = dst->src[1]; // Input
    const ggml_tensor * src2 = dst->src[2]; // Theta matrix
    
    ggml_cuda_nkat_star_gemm(src0, src1, src2, dst, ctx->stream());
}
#endif
```

### Step 5: GGUFæ‹¡å¼µå¯¾å¿œ

src/gguf.cppã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

```cpp
// NKAT metadata keys
static const char * GGUF_NKAT_VERSION = "nkat.version";
static const char * GGUF_NKAT_THETA_RANK = "nkat.theta_rank";
static const char * GGUF_NKAT_GAMMA_DECAY = "nkat.gamma_decay";

// NKAT tensor name patterns
static bool is_nkat_theta_tensor(const char* name) {
    return strstr(name, ".theta") != nullptr;
}
```

### Step 6: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«

```powershell
# ãƒ“ãƒ«ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir build
cd build

# CMakeè¨­å®šï¼ˆCUDAæœ‰åŠ¹åŒ–ï¼‰
cmake .. -DLLAMA_CUBLAS=ON -DCMAKE_BUILD_TYPE=Release

# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
cmake --build . --config Release -j 8
```

### Step 7: NKATæ¨è«–ãƒ†ã‚¹ãƒˆ

```powershell
# NKATãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
.\main.exe -m "..\NKAT_GGUF\output\nkat_test_model_enhanced.gguf" -p "Hello, world!" --nkat-enable

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
.\perplexity.exe -m "..\NKAT_GGUF\output\nkat_test_model_enhanced.gguf" -f wikitext-2-raw\wiki.test.raw
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼å¯¾å¿œ

1. **CUDA Compute Capability ã‚¨ãƒ©ãƒ¼**
```powershell
# RTX3080ã®å ´åˆã€8.6ã‚’æŒ‡å®š
set CUDAARCHS=86
```

2. **ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼**
```powershell
# ä¸¦åˆ—ã‚¸ãƒ§ãƒ–æ•°ã‚’æ¸›ã‚‰ã™
cmake --build . --config Release -j 4
```

3. **ãƒªãƒ³ã‚¯ã‚¨ãƒ©ãƒ¼**
```cpp
// nkat_cuda.hã§é–¢æ•°å®£è¨€ã‚’ç¢ºèª
extern "C" {
    void ggml_cuda_nkat_star_gemm(...);
}
```

### å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼å¯¾å¿œ

1. **NKATæ¼”ç®—å¤±æ•—**
```
Error: NKAT tensor not found
Solution: Î¸ãƒ†ãƒ³ã‚½ãƒ«ãŒå«ã¾ã‚ŒãŸGGUFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
```

2. **CUDA Out of Memory**
```
Solution: --low-vram ãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨
.\main.exe -m model.gguf -p "text" --low-vram
```

## ğŸ“Š æ€§èƒ½æ¤œè¨¼

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒ

```powershell
# æ¨™æº–æ¨è«–
.\main.exe -m base_model.gguf -p "Test prompt" -t 60 > baseline.txt

# NKATæ¨è«–
.\main.exe -m nkat_model.gguf -p "Test prompt" -t 60 --nkat-enable > nkat.txt

# çµæœæ¯”è¼ƒ
python compare_results.py baseline.txt nkat.txt
```

### æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„

| æŒ‡æ¨™ | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | NKAT | æ”¹å–„ç‡ |
|------|-------------|------|-------|
| Perplexity | 6.85 | 6.30 | -8% |
| æ¨è«–é€Ÿåº¦ | 35.2 tok/s | 29.9 tok/s | -15% |
| ç²¾åº¦ | - | +8% | +8% |

## ğŸŒŸ é«˜åº¦ãªä½¿ç”¨æ–¹æ³•

### NKATè¨­å®šã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

```cpp
// main.cppã§ã®NKATè¨­å®š
struct nkat_params {
    float theta_scale = 0.01f;     // Î¸ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
    int theta_rank = 4;            // Î¸ãƒ©ãƒ³ã‚¯è¨­å®š
    float gamma_decay = 0.97f;     // å±¤é–“æ¸›è¡°
    bool enable_star_product = true; // æ˜Ÿç©æ¼”ç®—æœ‰åŠ¹åŒ–
};
```

### æ¨è«–ãƒ¢ãƒ¼ãƒ‰é¸æŠ

```powershell
# ç²¾åº¦é‡è¦–ãƒ¢ãƒ¼ãƒ‰
.\main.exe -m model.gguf -p "text" --nkat-mode=precision

# é€Ÿåº¦é‡è¦–ãƒ¢ãƒ¼ãƒ‰  
.\main.exe -m model.gguf -p "text" --nkat-mode=speed

# ãƒãƒ©ãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰
.\main.exe -m model.gguf -p "text" --nkat-mode=balanced
```

## ğŸ”¬ ç†è«–èƒŒæ™¯

### Moyal Star Productå®Ÿè£…

```mathematical
y = (W â‹†_Î¸ x) := W exp(i/2 Î¸^{Î¼Î½} âˆ‚_Î¼ âˆ‚_Î½) x
â‰ˆ Wx + Â½i Î¸ (âˆ‚Wâˆ‚x - âˆ‚xâˆ‚W)
```

### CUDAå®Ÿè£…è©³ç´°

```cuda
__global__ void nkat_star_gemm_q8_v2_optimized(
    const int8_t* Aq,    // Weight matrix (quantized)
    const int8_t* Î¸q,    // Theta matrix (quantized) 
    const int8_t* xq,    // Input vector (quantized)
    const float scaleA, const float scaleÎ¸, const float scaleX,
    float* out,
    const int M, const int N, const int K
) {
    // éå¯æ›æ˜Ÿç©æ¼”ç®—ã®åŠ¹ç‡çš„å®Ÿè£…
    // RTX3080 Ampereã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æœ€é©åŒ–
}
```

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

çµ±åˆå¾Œã®llama.cppãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆï¼š

```
llama.cpp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ggml-cuda/
â”‚   â”‚   â”œâ”€â”€ nkat_star_gemm_kernels.cu    # NKATã‚«ãƒ¼ãƒãƒ«
â”‚   â”‚   â”œâ”€â”€ nkat_cuda_interface.cpp      # ãƒ›ã‚¹ãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
â”‚   â”‚   â”œâ”€â”€ nkat_cuda.h                  # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”‚   â””â”€â”€ ggml-cuda.cu                 # ä¿®æ­£æ¸ˆã¿ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ gguf.cpp                         # NKATæ‹¡å¼µå¯¾å¿œ
â”‚   â””â”€â”€ main.cpp                         # NKATè¨­å®šè¿½åŠ 
â”œâ”€â”€ build/                               # ãƒ“ãƒ«ãƒ‰å‡ºåŠ›
â”œâ”€â”€ CMakeLists.txt                       # NKATçµ±åˆè¨­å®š
â””â”€â”€ README.md                            # æ›´æ–°æ¸ˆã¿èª¬æ˜
```

## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **æ€§èƒ½æœ€é©åŒ–**: ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ”¹å–„
2. **æ©Ÿèƒ½æ‹¡å¼µ**: å‹•çš„Î¸ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
3. **æ¤œè¨¼å¼·åŒ–**: ã‚ˆã‚Šå¤šãã®ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒ†ã‚¹ãƒˆ
4. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: ç†è«–çš„èƒŒæ™¯ã®è©³ç´°èª¬æ˜

---

**æ³¨æ„**: çµ±åˆã«ã¯æ•°å­¦çš„ç†è«–ã®æ·±ã„ç†è§£ã¨CUDAãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®å°‚é–€çŸ¥è­˜ãŒå¿…è¦ã§ã™ã€‚ä¸æ˜ãªç‚¹ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€ç†è«–èª¬æ˜ã‹ã‚‰å®Ÿè£…è©³ç´°ã¾ã§è©³ã—ãã‚µãƒãƒ¼ãƒˆã„ãŸã—ã¾ã™ã€‚ 