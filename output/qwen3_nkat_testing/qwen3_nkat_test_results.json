{
  "model_info": {
    "path": "models/integrated/Qwen3-8B-ERP-v0.1.i1-Q6_K.gguf",
    "size_gb": 6.263982594013214
  },
  "vram_estimation": {
    "gpu_model": "NVIDIA GeForce RTX 3080",
    "total_vram_gb": 9.9993896484375,
    "model_size_gb": 6.263982594013214,
    "nkat_overhead_gb": 0.9395973891019821,
    "estimated_usage_gb": 8.203579983115196,
    "compatibility": "OK"
  },
  "test_results": [
    {
      "model": "Qwen3-8B-ERP (synthetic)",
      "seq_length": 256,
      "batch_size": 1,
      "device": "cuda",
      "avg_time_ms": 16.273999214172363,
      "avg_throughput_tokens_per_sec": 216798.50014886883,
      "throughput_std": 128595.17324231868,
      "memory_used_gb": 0.11145210266113281,
      "memory_reserved_gb": 0.146484375,
      "nkat_enabled": true
    },
    {
      "model": "Qwen3-8B-ERP (synthetic)",
      "seq_length": 512,
      "batch_size": 1,
      "device": "cuda",
      "avg_time_ms": 5.941367149353027,
      "avg_throughput_tokens_per_sec": 400843.1016612657,
      "throughput_std": 252530.3173139078,
      "memory_used_gb": 0.12121963500976562,
      "memory_reserved_gb": 0.146484375,
      "nkat_enabled": true
    },
    {
      "model": "Qwen3-8B-ERP (synthetic)",
      "seq_length": 1024,
      "batch_size": 1,
      "device": "cuda",
      "avg_time_ms": 2.460312843322754,
      "avg_throughput_tokens_per_sec": 445581.6498252068,
      "throughput_std": 115010.09375596521,
      "memory_used_gb": 0.14075469970703125,
      "memory_reserved_gb": 0.177734375,
      "nkat_enabled": true
    }
  ],
  "timestamp": "2025-06-02 12:15:16",
  "python_version": "3.12.9 (tags/v3.12.9:fdb8142, Feb  4 2025, 15:27:58) [MSC v.1942 64 bit (AMD64)]",
  "pytorch_version": "2.5.1+cu121"
}