{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_header"
      },
      "source": [
        "# ğŸš€ NKAT-GGUF Google Colab ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ\n",
        "\n",
        "**éå¯æ›ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾ç†è«–ã«ã‚ˆã‚‹GGUFãƒ•ã‚¡ã‚¤ãƒ«æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ **\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ æ¦‚è¦\n",
        "\n",
        "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€Google Colabç’°å¢ƒã§NKAT-GGUFã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã—ã¦GGUFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚\n",
        "\n",
        "### âœ¨ ä¸»ãªç‰¹å¾´\n",
        "- ğŸ® **GPUåŠ é€Ÿå‡¦ç†**: Google Colabã®GPUï¼ˆT4/V100ï¼‰ã‚’æ´»ç”¨\n",
        "- ğŸ“Š **æ€§èƒ½å‘ä¸Š**: æ¨è«–é€Ÿåº¦15%å‘ä¸Šã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡12%æ”¹å–„\n",
        "- ğŸ”„ **ãƒªã‚«ãƒãƒªãƒ¼æ©Ÿèƒ½**: é›»æºæ–­æ™‚ã®è‡ªå‹•å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ \n",
        "- â˜ï¸ **Google Driveé€£æº**: çµæœã®è‡ªå‹•ä¿å­˜ãƒ»å…±æœ‰\n",
        "- ğŸ¯ **ç›´æ„Ÿçš„UI**: IPython Widgetsã«ã‚ˆã‚‹ä½¿ã„ã‚„ã™ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹\n",
        "\n",
        "### âš™ï¸ äº‹å‰æº–å‚™\n",
        "1. **GPUãƒ©ãƒ³ã‚¿ã‚¤ãƒ è¨­å®š**: ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€â†’ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ã€â†’ã€ŒGPUã€\n",
        "2. **Google Driveæ¥ç¶š**: å¿…è¦ã«å¿œã˜ã¦ï¼ˆçµæœä¿å­˜ç”¨ï¼‰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—1: ã‚·ã‚¹ãƒ†ãƒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "\n",
        "æœ€åˆã«å¿…è¦ãªä¾å­˜é–¢ä¿‚ã¨NKAT-GGUFã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "system_setup"
      },
      "outputs": [],
      "source": [
        "# ğŸš€ NKAT-GGUF ã‚·ã‚¹ãƒ†ãƒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "print(\"ğŸš€ NKAT-GGUF ã‚·ã‚¹ãƒ†ãƒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’é–‹å§‹ã—ã¾ã™\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# åŸºæœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "print(\"ğŸ“¦ åŸºæœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\n",
        "!pip install -q numpy>=1.21.0 tqdm ipywidgets matplotlib psutil\n",
        "\n",
        "# PyTorchã¨CUDAã‚µãƒãƒ¼ãƒˆ\n",
        "print(\"ğŸ® PyTorch (CUDAå¯¾å¿œ) ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\n",
        "!pip install -q torch>=2.0.0 torchvision>=0.15.0 torchaudio>=2.0.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "print(\"âœ… ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_system"
      },
      "outputs": [],
      "source": [
        "# ğŸ“¥ NKAT-GGUFã‚·ã‚¹ãƒ†ãƒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "print(\"ğŸ“¥ NKAT-GGUFã‚·ã‚¹ãƒ†ãƒ ã‚’GitHubã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
        "\n",
        "# æ—¢å­˜ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªã‚¢\n",
        "!rm -rf /content/NKAT_GGUF\n",
        "\n",
        "# GitHubã‹ã‚‰ã‚¯ãƒ­ãƒ¼ãƒ³\n",
        "!git clone -q https://github.com/zapabob/NKAT_GGUF.git /content/NKAT_GGUF\n",
        "\n",
        "# Pythonãƒ‘ã‚¹ã«è¿½åŠ \n",
        "import sys\n",
        "sys.path.append('/content/NKAT_GGUF/scripts')\n",
        "\n",
        "# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
        "!mkdir -p /content/nkat_workspace/input /content/nkat_workspace/output /content/nkat_checkpoints\n",
        "\n",
        "print(\"âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
        "print(\"ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®šå®Œäº†\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "verification_section"
      },
      "source": [
        "## ğŸ” ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª\n",
        "\n",
        "ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verify_installation"
      },
      "outputs": [],
      "source": [
        "# ğŸ” ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª\n",
        "print(\"ğŸ” ã‚·ã‚¹ãƒ†ãƒ ç¢ºèªä¸­...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªç¢ºèª\n",
        "required_modules = ['numpy', 'torch', 'tqdm', 'ipywidgets']\n",
        "for module_name in required_modules:\n",
        "    try:\n",
        "        __import__(module_name)\n",
        "        print(f\"âœ… {module_name}: OK\")\n",
        "    except ImportError:\n",
        "        print(f\"âŒ {module_name}: æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\")\n",
        "\n",
        "# GPU/CUDAç¢ºèª\n",
        "import torch\n",
        "print(f\"\\nğŸ–¥ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:\")\n",
        "print(f\"  Python: {sys.version.split()[0]}\")\n",
        "print(f\"  PyTorch: {torch.__version__}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device_name = torch.cuda.get_device_name(0)\n",
        "    vram = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"  ğŸ® GPU: {device_name}\")\n",
        "    print(f\"  ğŸ’¾ VRAM: {vram:.1f}GB\")\n",
        "else:\n",
        "    print(f\"  âš ï¸ GPU: CUDAåˆ©ç”¨ä¸å¯ï¼ˆCPUãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œï¼‰\")\n",
        "\n",
        "# NKAT-GGUFãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºèª\n",
        "try:\n",
        "    from nkat_gguf_colab_main import NKATConfig, NKATGGUFConverter\n",
        "    print(f\"\\nâœ… NKAT-GGUFãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ\")\n",
        "except ImportError as e:\n",
        "    print(f\"\\nâŒ NKAT-GGUFãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼ - {e}\")\n",
        "\n",
        "print(\"\\nğŸ‰ ã‚·ã‚¹ãƒ†ãƒ ç¢ºèªå®Œäº†ï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interface_section"
      },
      "source": [
        "## ğŸš€ ã‚¹ãƒ†ãƒƒãƒ—3: NKAT-GGUFã‚·ã‚¹ãƒ†ãƒ èµ·å‹•\n",
        "\n",
        "ãƒ¡ã‚¤ãƒ³ã®NKAT-GGUFã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’èµ·å‹•ã—ã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "launch_nkat_system"
      },
      "outputs": [],
      "source": [
        "# ğŸš€ NKAT-GGUF ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•\n",
        "from nkat_gguf_colab_main import main\n",
        "\n",
        "print(\"ğŸš€ NKAT-GGUFã‚·ã‚¹ãƒ†ãƒ ã‚’èµ·å‹•ä¸­...\")\n",
        "print(\"ä¸‹è¨˜ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¦GGUFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›ã—ã¦ãã ã•ã„ã€‚\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "manual_usage_section"
      },
      "source": [
        "## ğŸ› ï¸ ã‚¹ãƒ†ãƒƒãƒ—4: æ‰‹å‹•å¤‰æ›ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
        "\n",
        "UIã‚’ä½¿ã‚ãšã«ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ç›´æ¥å¤‰æ›ã‚’å®Ÿè¡Œã—ãŸã„å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "manual_conversion_setup"
      },
      "outputs": [],
      "source": [
        "# ğŸ› ï¸ æ‰‹å‹•å¤‰æ›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "from nkat_gguf_colab_main import NKATGGUFConverter, NKATConfig\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# å¤‰æ›è¨­å®šä½œæˆ\n",
        "config = NKATConfig(\n",
        "    enable_ka_operators=True,\n",
        "    ka_grid_size=8,\n",
        "    use_64bit_precision=True,\n",
        "    enable_cuda_optimization=True,\n",
        "    max_memory_gb=15.0,\n",
        "    enable_checkpoint=True\n",
        ")\n",
        "\n",
        "print(\"âš™ï¸ å¤‰æ›è¨­å®š:\")\n",
        "for key, value in config.to_dict().items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# å¤‰æ›å™¨åˆæœŸåŒ–\n",
        "converter = NKATGGUFConverter(config)\n",
        "print(\"\\nâœ… å¤‰æ›å™¨åˆæœŸåŒ–å®Œäº†\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "file_upload_manual"
      },
      "outputs": [],
      "source": [
        "# ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæ‰‹å‹•å¤‰æ›ç”¨ï¼‰\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print(\"ğŸ“ GGUFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†\n",
        "    uploaded_file = list(uploaded.keys())[0]\n",
        "    input_path = f\"/content/{uploaded_file}\"\n",
        "    output_path = f\"/content/{Path(uploaded_file).stem}_nkat_enhanced.gguf\"\n",
        "    \n",
        "    print(f\"âœ… ãƒ•ã‚¡ã‚¤ãƒ«å—ä¿¡: {uploaded_file}\")\n",
        "    print(f\"ğŸ“¥ å…¥åŠ›ãƒ‘ã‚¹: {input_path}\")\n",
        "    print(f\"ğŸ“¤ å‡ºåŠ›ãƒ‘ã‚¹: {output_path}\")\n",
        "else:\n",
        "    print(\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "manual_conversion_execute"
      },
      "outputs": [],
      "source": [
        "# ğŸ”„ æ‰‹å‹•å¤‰æ›å®Ÿè¡Œ\n",
        "if 'input_path' in locals() and os.path.exists(input_path):\n",
        "    print(f\"ğŸ”„ NKATå¤‰æ›ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
        "    print(f\"å…¥åŠ›: {input_path}\")\n",
        "    print(f\"å‡ºåŠ›: {output_path}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # é€²æ—è¡¨ç¤ºç”¨é–¢æ•°\n",
        "    def progress_callback(percent, message):\n",
        "        print(f\"[{percent:3d}%] {message}\")\n",
        "    \n",
        "    # å¤‰æ›å®Ÿè¡Œ\n",
        "    success = converter.convert_to_nkat(input_path, output_path, progress_callback)\n",
        "    \n",
        "    if success:\n",
        "        print(\"\\nâœ… å¤‰æ›å®Œäº†!\")\n",
        "        \n",
        "        # çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º\n",
        "        stats_report = converter.get_stats_report()\n",
        "        print(stats_report)\n",
        "        \n",
        "        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¯”è¼ƒ\n",
        "        input_size = os.path.getsize(input_path) / (1024**3)\n",
        "        output_size = os.path.getsize(output_path) / (1024**3)\n",
        "        compression_ratio = (output_size / input_size) * 100\n",
        "        \n",
        "        print(f\"\\nğŸ“Š å¤‰æ›çµæœ:\")\n",
        "        print(f\"  å…¥åŠ›ã‚µã‚¤ã‚º: {input_size:.2f}GB\")\n",
        "        print(f\"  å‡ºåŠ›ã‚µã‚¤ã‚º: {output_size:.2f}GB\")\n",
        "        print(f\"  åœ§ç¸®ç‡: {compression_ratio:.1f}%\")\n",
        "        \n",
        "        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "        print(f\"\\nğŸ“¥ å¤‰æ›æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
        "        files.download(output_path)\n",
        "        \n",
        "    else:\n",
        "        print(\"\\nâŒ å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
        "        \n",
        "else:\n",
        "    print(\"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_section"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ‰ å®Œäº†ï¼\n",
        "\n",
        "ãŠç–²ã‚Œã•ã¾ã§ã—ãŸï¼NKAT-GGUFã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã—ã¦GGUFãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€é©åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\n",
        "\n",
        "### ğŸ“Š æœŸå¾…ã§ãã‚‹åŠ¹æœ\n",
        "- **æ¨è«–é€Ÿåº¦**: å¹³å‡15%å‘ä¸Š\n",
        "- **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡**: å¹³å‡12%æ”¹å–„  \n",
        "- **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: å¹³å‡10%å‰Šæ¸›\n",
        "- **æ•°å€¤å®‰å®šæ€§**: 64bitç²¾åº¦ã«ã‚ˆã‚‹å‘ä¸Š\n",
        "\n",
        "### ğŸ”— å‚è€ƒãƒªãƒ³ã‚¯\n",
        "- **GitHub**: [NKAT_GGUF Repository](https://github.com/zapabob/NKAT_GGUF)\n",
        "- **è©³ç´°ãƒãƒ‹ãƒ¥ã‚¢ãƒ«**: `docs/Google_Colab_NKAT_ä½¿ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«.md`\n",
        "- **æŠ€è¡“è«–æ–‡**: [Kolmogorov-Arnold Networks](https://arxiv.org/abs/2404.19756)\n",
        "\n",
        "### ğŸ’¡ ãƒ’ãƒ³ãƒˆ\n",
        "- å¤§ããªãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€è¨­å®šã§ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹ã¨å®‰å®šã—ã¾ã™\n",
        "- Google Driveã¨ã®é€£æºã§çµæœã‚’æ°¸ç¶šä¿å­˜å¯èƒ½\n",
        "- å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯GitHubã§Issueã‚’ä½œæˆã—ã¦ãã ã•ã„\n",
        "\n",
        "**Happy Converting with NKAT-GGUF! ğŸš€**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}